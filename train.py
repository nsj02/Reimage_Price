"""
train.py - CNN ëª¨ë¸ í›ˆë ¨ ë° ì„±ëŠ¥ ì‹œê°í™” ëª¨ë“ˆ

ì´ íŒŒì¼ì€ ìº”ë“¤ì°¨íŠ¸ ì´ë¯¸ì§€ë¡œ ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” í•µì‹¬ ê¸°ëŠ¥ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤:
- ëª¨ë¸ í›ˆë ¨ ë° ê²€ì¦ ë£¨í”„
- ì¡°ê¸° ì¢…ë£Œ (Early Stopping) ê¸°ëŠ¥
- í›ˆë ¨ ê³¼ì • ì‹œê°í™” (ì†ì‹¤/ì •í™•ë„ ê·¸ë˜í”„)
"""
from __init__ import *

# GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ CUDA, ì—†ìœ¼ë©´ CPU ì‚¬ìš©
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def train_n_epochs(n_epochs, model, label_type, train_loader, valid_loader, criterion, optimizer, savefile, early_stop_epoch):
    """
    CNN ëª¨ë¸ì„ ì§€ì •ëœ ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ì‹œí‚¤ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ğŸ‹ï¸ ë§¤ ì—í¬í¬ë§ˆë‹¤ í›ˆë ¨ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
    2. ğŸ“Š ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€  
    3. ğŸ’¾ ì„±ëŠ¥ì´ í–¥ìƒë  ë•Œë§ˆë‹¤ ìµœì  ëª¨ë¸ ì €ì¥
    4. â° ì„±ëŠ¥ í–¥ìƒì´ ë©ˆì¶”ë©´ ì¡°ê¸° ì¢…ë£Œ (ê³¼ì í•© ë°©ì§€)
    
    Args:
        n_epochs (int): ìµœëŒ€ í›ˆë ¨ ì—í¬í¬ ìˆ˜
        model: í›ˆë ¨í•  CNN ëª¨ë¸ (CNN5d, CNN20d, ë˜ëŠ” CNN60d)
        label_type (str): ì˜ˆì¸¡ ë¼ë²¨ íƒ€ì… ('RET5', 'RET20', ë˜ëŠ” 'RET60')
        train_loader: í›ˆë ¨ ë°ì´í„° ë¡œë”
        valid_loader: ê²€ì¦ ë°ì´í„° ë¡œë”  
        criterion: ì†ì‹¤ í•¨ìˆ˜ (CrossEntropyLoss)
        optimizer: ìµœì í™” ì•Œê³ ë¦¬ì¦˜ (ì˜ˆ: Adam)
        savefile (str): ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        early_stop_epoch (int): ì¡°ê¸° ì¢…ë£Œ ê¸°ì¤€ ì—í¬í¬ ìˆ˜
    
    Returns:
        tuple: (í›ˆë ¨ì†ì‹¤, ê²€ì¦ì†ì‹¤, í›ˆë ¨ì •í™•ë„, ê²€ì¦ì •í™•ë„) íˆìŠ¤í† ë¦¬
    """
    # === ì„±ëŠ¥ ì¶”ì  ë³€ìˆ˜ë“¤ ì´ˆê¸°í™” ===
    valid_loss_min = np.inf        # ìµœê³  ì„±ëŠ¥(ìµœì†Œ ê²€ì¦ ì†ì‹¤) ì¶”ì 
    train_loss_set = []            # ì—í¬í¬ë³„ í›ˆë ¨ ì†ì‹¤ ê¸°ë¡
    valid_loss_set = []            # ì—í¬í¬ë³„ ê²€ì¦ ì†ì‹¤ ê¸°ë¡
    train_acc_set = []             # ì—í¬í¬ë³„ í›ˆë ¨ ì •í™•ë„ ê¸°ë¡
    valid_acc_set = []             # ì—í¬í¬ë³„ ê²€ì¦ ì •í™•ë„ ê¸°ë¡
    invariant_epochs = 0           # ì„±ëŠ¥ í–¥ìƒì´ ì—†ëŠ” ì—í¬í¬ ì¹´ìš´í„° (ì¡°ê¸° ì¢…ë£Œìš©)
    
    # === ë©”ì¸ í›ˆë ¨ ë£¨í”„: ì§€ì •ëœ ì—í¬í¬ë§Œí¼ ë°˜ë³µ ===
    for epoch_i in range(1, n_epochs+1):
        
        # í˜„ì¬ ì—í¬í¬ì˜ ì†ì‹¤/ì •í™•ë„ ì´ˆê¸°í™”
        train_loss, train_acc = 0.0, 0.0
        valid_loss, valid_acc = 0.0, 0.0
        
        # ============== ğŸ‹ï¸ í›ˆë ¨ ë‹¨ê³„ (Training Phase) ==============
        model.train()  # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì • (Dropout, BatchNorm í™œì„±í™”)
        
        for i, (data, ret5, ret20, ret60, _, _, _) in enumerate(train_loader):
            # ë¼ë²¨ íƒ€ì…ì— ë”°ë¼ ì˜ˆì¸¡ íƒ€ê²Ÿ ì„ íƒ
            assert label_type in ['RET5', 'RET20', 'RET60'], f"ì˜ëª»ëœ ë¼ë²¨ íƒ€ì…: {label_type}"
            if label_type == 'RET5':
                target = ret5
            elif label_type == 'RET20':
                target = ret20
            else:  # RET60
                target = ret60

            # CrossEntropyLossìš© ë¼ë²¨ (ì›-í•« ì¸ì½”ë”© ë¶ˆí•„ìš”)
            target = target.long()

            # GPUë¡œ ë°ì´í„° ì´ë™
            data, target = data.to(device), target.to(device)
            
            # ê²½ì‚¬ë„ ì´ˆê¸°í™” (ì´ì „ ë°°ì¹˜ì˜ ê²½ì‚¬ë„ ì œê±°)
            optimizer.zero_grad()
            
            # ìˆœì „íŒŒ: ëª¨ë¸ì— ì…ë ¥ì„ ë„£ì–´ ì˜ˆì¸¡ê°’ ê³„ì‚°
            output = model(data)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = criterion(output, target)
            
            # ì—­ì „íŒŒ: ì†ì‹¤ì— ëŒ€í•œ ê²½ì‚¬ë„ ê³„ì‚°
            loss.backward()
            
            # ê²½ì‚¬ë„ë¥¼ ì´ìš©í•œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            optimizer.step()
            
            # ì„±ëŠ¥ ì§€í‘œ ëˆ„ì 
            train_loss += loss.item() * data.size(0)  # ê°€ì¤‘ í‰ê· ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ê³±í•¨
            train_acc += (output.argmax(1) == target).sum()  # ì˜ˆì¸¡ê³¼ ì‹¤ì œ ë¹„êµ

        # ============== ğŸ“Š ê²€ì¦ ë‹¨ê³„ (Validation Phase) ==============
        model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • (Dropout ë¹„í™œì„±í™”, BatchNorm ê³ ì •)
        
        with torch.no_grad():  # ê²€ì¦ ë‹¨ê³„ì—ì„œëŠ” ê²½ì‚¬ë„ ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
            for i, (data, ret5, ret20, ret60, _, _, _) in enumerate(valid_loader):
                # í›ˆë ¨ ë‹¨ê³„ì™€ ë™ì¼í•œ ë¼ë²¨ ì²˜ë¦¬
                assert label_type in ['RET5', 'RET20', 'RET60'], f"ì˜ëª»ëœ ë¼ë²¨ íƒ€ì…: {label_type}"
                if label_type == 'RET5':
                    target = ret5
                elif label_type == 'RET20':
                    target = ret20
                else:  # RET60
                    target = ret60
                    
                # CrossEntropyLossìš© ë¼ë²¨ (ì›-í•« ì¸ì½”ë”© ë¶ˆí•„ìš”)
                target = target.long()
                    
                # GPUë¡œ ë°ì´í„° ì´ë™
                data, target = data.to(device), target.to(device)
                
                # ìˆœì „íŒŒë§Œ ìˆ˜í–‰ (ì—­ì „íŒŒ ì—†ìŒ)
                output = model(data)
                loss = criterion(output, target)
                
                # ê²€ì¦ ì„±ëŠ¥ ì§€í‘œ ëˆ„ì 
                valid_loss += loss.item() * data.size(0)
                valid_acc += (output.argmax(1) == target).sum()
        
        # ============== ğŸ“ˆ ì—í¬í¬ë³„ ì„±ëŠ¥ ê³„ì‚° ë° ê¸°ë¡ ==============
        
        # í‰ê·  ì†ì‹¤ ê³„ì‚° (ì „ì²´ ìƒ˜í”Œ ìˆ˜ë¡œ ë‚˜ëˆ„ê¸°)
        train_loss = train_loss / len(train_loader.dataset)
        train_loss_set.append(train_loss)
        valid_loss = valid_loss / len(valid_loader.dataset)
        valid_loss_set.append(valid_loss)

        # í‰ê·  ì •í™•ë„ ê³„ì‚° ë° ê¸°ë¡
        train_acc = train_acc / len(train_loader.dataset)
        train_acc_set.append(train_acc.detach().cpu().numpy())
        valid_acc = valid_acc / len(valid_loader.dataset)
        valid_acc_set.append(valid_acc.detach().cpu().numpy())
            
        # í˜„ì¬ ì—í¬í¬ ì„±ëŠ¥ ì¶œë ¥
        print('Epoch: {} Training Loss: {:.6f} Validation Loss: {:.6f} Training Acc: {:.5f} Validation Acc: {:.5f}'.format(
            epoch_i, train_loss, valid_loss, train_acc, valid_acc))
        
        # ============== ğŸ’¾ ëª¨ë¸ ì €ì¥ ë° ì¡°ê¸° ì¢…ë£Œ ë¡œì§ ==============
        
        # ê²€ì¦ ì†ì‹¤ì´ ê°œì„ ë˜ë©´ ëª¨ë¸ ì €ì¥
        if valid_loss <= valid_loss_min:
            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))
            valid_loss_min = valid_loss
            invariant_epochs = 0  # ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ì¹´ìš´í„° ë¦¬ì…‹
            
            # ëª¨ë¸, ì—í¬í¬, ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ì €ì¥
            torch.save({
                'epoch': epoch_i,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict()
            }, savefile)
        else:
            # ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€
            invariant_epochs += 1
        
        # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì²´í¬
        if invariant_epochs >= early_stop_epoch:
            print(f"Early Stop at Epoch [{epoch_i}]: Performance hasn't enhanced for {early_stop_epoch} epochs")
            break

    # í›ˆë ¨ ê³¼ì •ì˜ ëª¨ë“  ì„±ëŠ¥ ê¸°ë¡ ë°˜í™˜
    return train_loss_set, valid_loss_set, train_acc_set, valid_acc_set



def plot_loss_and_acc(loss_and_acc_dict):
    """
    í›ˆë ¨ ê³¼ì •ì˜ ì†ì‹¤ ë° ì •í™•ë„ ë³€í™”ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜
    
    ğŸ“Š ë‘ ê°œì˜ ê·¸ë˜í”„ë¥¼ ë‚˜ë€íˆ ìƒì„±:
    - ì™¼ìª½: ì—í¬í¬ë³„ ì†ì‹¤(Loss) ë³€í™” ì¶”ì´
    - ì˜¤ë¥¸ìª½: ì—í¬í¬ë³„ ì •í™•ë„(Accuracy) ë³€í™” ì¶”ì´
    
    Args:
        loss_and_acc_dict (dict): ê° ë°ì´í„°ì…‹ë³„ [ì†ì‹¤ë¦¬ìŠ¤íŠ¸, ì •í™•ë„ë¦¬ìŠ¤íŠ¸] ë”•ì…”ë„ˆë¦¬
                                  ì˜ˆ: {'train': ([ì†ì‹¤ë“¤], [ì •í™•ë„ë“¤]), 'valid': ([ì†ì‹¤ë“¤], [ì •í™•ë„ë“¤])}
    
    ì£¼ìš” ê¸°ëŠ¥:
    - í›ˆë ¨/ê²€ì¦ ì„±ëŠ¥ì„ í•œëˆˆì— ë¹„êµ ê°€ëŠ¥
    - ê³¼ì í•© ì—¬ë¶€ íŒë‹¨ (ê²€ì¦ ì†ì‹¤ì´ í›ˆë ¨ ì†ì‹¤ë³´ë‹¤ ë†’ì•„ì§€ëŠ” ì§€ì )
    - í•™ìŠµ ìˆ˜ë ´ ìƒíƒœ í™•ì¸
    """
    # 2ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„± (1í–‰ 2ì—´, ê°€ë¡œë¡œ ë°°ì¹˜)
    _, axes = plt.subplots(1, 2, figsize=(20, 6))
    
    # ì²« ë²ˆì§¸ ë°ì´í„°ì…‹ì˜ ì†ì‹¤ ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ì´ ì—í¬í¬ ìˆ˜ ê³„ì‚°
    tmp = list(loss_and_acc_dict.values())
    maxEpoch = len(tmp[0][0])

    # ========== ì™¼ìª½ ê·¸ë˜í”„: ì†ì‹¤(Loss) ì‹œê°í™” ==========
    
    # Yì¶• ë²”ìœ„ ìë™ ì„¤ì • (ëª¨ë“  ë°ì´í„°ì…‹ì˜ ìµœëŒ€/ìµœì†Œ ì†ì‹¤ ê¸°ì¤€)
    maxLoss = max([max(x[0]) for x in loss_and_acc_dict.values()]) + 0.1
    minLoss = max(0, min([min(x[0]) for x in loss_and_acc_dict.values()]) - 0.1)

    # ê° ë°ì´í„°ì…‹(í›ˆë ¨/ê²€ì¦)ë³„ë¡œ ì†ì‹¤ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    for name, lossAndAcc in loss_and_acc_dict.items():
        axes[0].plot(range(1, 1 + maxEpoch), lossAndAcc[0], '-s', label=name)

    # ì†ì‹¤ ê·¸ë˜í”„ ì„¤ì •
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_xticks(range(0, maxEpoch + 1, max(1, maxEpoch//10)))  # Xì¶• ëˆˆê¸ˆ (ìµœì†Œ ê°„ê²© 1)
    axes[0].axis([0, maxEpoch, minLoss, maxLoss])
    axes[0].legend()
    axes[0].set_title("Training & Validation Loss")

    # ========== ì˜¤ë¥¸ìª½ ê·¸ë˜í”„: ì •í™•ë„(Accuracy) ì‹œê°í™” ==========
    
    # Yì¶• ë²”ìœ„ ìë™ ì„¤ì • (ì •í™•ë„ëŠ” 0~1 ì‚¬ì´ì´ë¯€ë¡œ ë²”ìœ„ ì œí•œ)
    maxAcc = min(1, max([max(x[1]) for x in loss_and_acc_dict.values()]) + 0.1)
    minAcc = max(0, min([min(x[1]) for x in loss_and_acc_dict.values()]) - 0.1)

    # ê° ë°ì´í„°ì…‹ë³„ë¡œ ì •í™•ë„ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°  
    for name, lossAndAcc in loss_and_acc_dict.items():
        axes[1].plot(range(1, 1 + maxEpoch), lossAndAcc[1], '-s', label=name)

    # ì •í™•ë„ ê·¸ë˜í”„ ì„¤ì •
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_xticks(range(0, maxEpoch + 1, max(1, maxEpoch//10)))  # Xì¶• ëˆˆê¸ˆ
    axes[1].axis([0, maxEpoch, minAcc, maxAcc])
    axes[1].legend()
    axes[1].set_title("Training & Validation Accuracy")
    
    # ê·¸ë˜í”„ í‘œì‹œ
    plt.tight_layout()  # ì„œë¸Œí”Œë¡¯ ê°„ê²© ìë™ ì¡°ì •
    plt.show()