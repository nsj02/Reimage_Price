# ✅ ReImaging_Price_Trends vs trend_submit 종합 차이 분석 및 수정 진행 현황
# 📅 업데이트: 2025-01-13 - 통합 캘린더 샘플링 구현 완료

## 📅 진행 현황 타임라인

### ✅ 2025-01-13 통합 캘린더 샘플링 구현 완료
1. **데이터 샘플링 방식 근본 개선**
   - ✅ 기존: 주식별 개별 윈도우 (231개 날짜) → 현실성 부족
   - ✅ 신규: 통합 캘린더 기반 20일 윈도우 (101개 날짜) → 현실적 리밸런싱
   - ✅ 모든 주식이 동일한 거래일 기준으로 차트 생성
   - ✅ Non-overlapping 윈도우로 데이터 독립성 확보

2. **성능 최적화 및 진행률 표시**
   - ✅ 반복문 구조 개선: 날짜별 → 주식별 처리로 변경
   - ✅ 사전 그룹핑으로 중복 필터링 제거
   - ✅ tqdm 진행률 표시 복구
   - ✅ 예상 처리 시간: 11,752 주식 × 101 윈도우 = 약 2시간

3. **메모리 효율성 검증**
   - ✅ 전체 이미지 메모리 누적 후 년도별 분류 저장 방식 유지
   - ✅ 년도별 직접 처리 대신 현재 방식으로 안정성 확보
   - ✅ 진행 상황: 11,752 주식 중 1,202개 완료 (10%, 1.25it/s)

### ✅ 2025-01-12 해결 완료
1. **데이터 통합 및 연속성 문제 해결**
   - ✅ 1992-2019 전체 기간 통합 데이터 생성 (`data_1992_2019_unified.parquet`)
   - ✅ equity_data.py 방식 전처리 적용 (컬럼명 변경, MultiIndex, 데이터 타입 변환)
   - ✅ 연속적 EWMA 변동성 계산 (`lambda x: (x**2).ewm(alpha=0.05).mean().shift(periods=1)`)
   - ✅ 누적 로그 수익률 기반 미래 수익률 계산 (`np.exp(x.shift(-i) - x) - 1`)

2. **데이터 품질 개선**
   - ✅ CRSP 음수 가격 처리 (절댓값 변환)
   - ✅ 무효값 NaN 처리 (0, "C", "B", "A", "." → np.nan)
   - ✅ 데이터 타입 표준화 (StockID → str, Ret → numeric)
   - ✅ EDA 분석 추가 (분포도, 상승/하락 비율, 시계열 분석)

### ✅ 2025-01-12 완료 (오후 작업)
3. **이미지 생성 알고리즘 수정** - 🎉 완료
   - ✅ chart_library.py의 DrawOHLC 로직 dataset.py에 완전 적용
   - ✅ PIL 기반 이미지 생성으로 변경 (generate_chart_image_pil 함수)
   - ✅ 원본 좌표계 + 최종 이미지 뒤집기 적용 (image.transpose(Image.FLIP_TOP_BOTTOM))
   - ✅ High-Low bar 굵게 그리기, Open/Close 수평선 구현 완료

4. **가격 정규화 방식 수정** - 🎉 완료
   - ✅ adjust_price_trend_submit() 함수 완전 복제 (generate_chart.py Lines 107-165)
   - ✅ 첫날 종가=1.0 기준 정규화 구현
   - ✅ Min-Max 스케일링 완전 제거
   - ✅ 수익률 기반 가격 재구성 로직 적용

### ✅ 2025-01-12 완료 (오후 작업 - 파일 구조 정리)
5. **차트 생성 파일 구조 개선** - 🎉 완료
   - ✅ chart_library.py 생성 (DrawOHLC 클래스만 포함, 깔끔한 분리)
   - ✅ chart_generator.py 생성 (메인 이미지 생성 스크립트, adjust_price 포함)
   - ✅ 불필요 파일 삭제 (stock_data_processor.py, chart_image_generator.py)
   - ✅ ipynb 파일명 변경 (기능별 명확한 이름):
     * 1_image_generation.ipynb → chart_image_generation.ipynb
     * datageneration.ipynb → data_processing_and_unification.ipynb

6. **데이터 파이프라인 통합**
   - ✅ data_1992_2019_unified.parquet 파일 사용으로 변경
   - ✅ chart_image_generation.ipynb에서 chart_generator.py 호출하도록 수정
   - ✅ 파일 구조 trend_submit과 동일하게 분리 (chart_library + chart_generator)

### 📋 다음 예정 작업

7. **성능 검증**
   - ⏳ chart_image_generation.ipynb 실행 테스트
   - ⏳ 새 구조로 이미지 생성 검증
   - ⏳ 샘플 이미지 원본 대비 비교
   - ⏳ 백테스팅 성능 확인 (-1.93 → +2.16 목표)

## 🔍 1. 근본적 구조 차이 (✅ 해결됨)

### A. 데이터 파이프라인 차이 - ✅ 해결
**기존 ReImaging_Price_Trends:**
```
WRDS 파케이 파일 → dataset.py → 차트 생성 → PyTorch 로더
```

**✅ 수정된 ReImaging_Price_Trends (2025-01-12):**
```
WRDS 원시 데이터 → equity_data.py 방식 전처리 → 통합 데이터 → dataset.py → 차트 생성
```

**trend_submit (논문 저자):**
```
CRSP 원시 데이터 → equity_data.py → generate_chart.py → chart_dataset.py → PyTorch 로더
```

**✅ 해결 완료:** 
- equity_data.py와 동일한 전처리 로직 적용
- 원시 데이터부터 전체 처리 과정 구현
- 데이터 품질과 전처리 방식 일치

### B. 데이터 연속성 문제 - ✅ 해결  
**✅ 수정된 ReImaging_Price_Trends (2025-01-12):**
- `data_1992_2019_unified.parquet` (통합 연속 데이터)
- 1992년부터 전체 기간 포함 (이동평균 계산용 lookback 데이터)
- EWMA 변동성이 연속 계산됨

**trend_submit:**
- 전체 기간 연속 데이터 (1992~2019)
- EWMA 변동성이 연속 계산됨
- 이동평균 계산에 필요한 이전 데이터 항상 존재

## 🚨 2. 치명적 차이점들 (성능에 직접 영향) - ⏳ 수정 중

### A. 가격 정규화 방식 - ❌ 아직 미해결 (최우선 수정 필요)
**현재 ReImaging (여전히 틀림):**
```python
# 전역 Min-Max 정규화 → 모든 값이 0~1 범위
price_slice = (normalized_prices - price_min) / (price_max - price_min)
# 문제: 차트마다 스케일이 다름, 상대적 움직임 왜곡
```

**trend_submit (정답):**
```python
# adjust_price(): 첫날 종가=1.0, 수익률로 재구성
res_df.at[0, "Close"] = 1.0
res_df.at[i, "Close"] = (1 + today_ret) * pre_close
# 마지막에 차트 시작점으로 정규화
data *= (1.0 / data["Close"].loc[start_date_index])
# 장점: 모든 차트가 동일한 시작점, 상대적 움직임 보존
```

**🔥 이 차이가 성능 차이의 주요 원인 - 즉시 수정 필요**

### B. 결측치 처리 방식 - ✅ 부분 해결 (datageneration.ipynb에서)
**✅ 수정된 ReImaging (2025-01-12):**
```python
# equity_data.py 방식으로 엄격하게 처리
df = df.replace({
    "Close": {0: np.nan},   
    "Open": {0: np.nan},
    "High": {0: np.nan},
    "Low": {0: np.nan},
    "Ret": {"C": np.nan, "B": np.nan, "A": np.nan, ".": np.nan},
})
df = df.dropna(subset=["Ret"])  # 무효한 수익률 제거
```

**trend_submit (엄격함):**
```python
if data["Close"].iloc[0] == 0.0 or pd.isna(data["Close"].iloc[0]):
    return 2  # 전체 윈도우 폐기
```

**✅ 해결됨: 데이터 품질 크게 개선됨**

### C. Y축 좌표 변환 - ❌ 아직 미해결 (이미지 생성 단계)
**현재 ReImaging (여전히 잘못됨):**
```python
# 직접 Y축 뒤집기
image[price_region_end - open_px, i*3] = 255
```

**trend_submit (정답):**
```python
# 정상 좌표 계산 후 이미지 전체 뒤집기
pixels_per_unit = (self.ohlc_height - 1.0) / (self.maxp - self.minp)
res = np.around((ret - self.minp) * pixels_per_unit)
# 마지막에 이미지 뒤집기
image = image.transpose(Image.FLIP_TOP_BOTTOM)
```

**⏳ 다음 수정 예정 - dataset.py 이미지 생성 부분**

## 🔧 3. 복제해야 할 핵심 코드들 - 진행 현황

### A. equity_data.py의 EWMA 계산 로직 - ✅ 완료 (2025-01-12)
```python
# ✅ datageneration.ipynb에서 완전히 구현됨
df["EWMA_vol"] = df.groupby("StockID")["Ret"].transform(
    lambda x: (x**2).ewm(alpha=0.05).mean().shift(periods=1)
)
# ✅ 누적 로그 수익률도 함께 구현
df["log_ret"] = np.log(1 + df.Ret)
df["cum_log_ret"] = df.groupby("StockID")["log_ret"].cumsum(skipna=True)
```

### B. generate_chart.py의 adjust_price() 함수 - ✅ 완료 (2025-01-12)
```python
# ✅ dataset.py에 adjust_price_trend_submit() 함수로 완전 구현됨
def adjust_price_trend_submit(df):
    """trend_submit의 adjust_price() 메서드를 정확히 복제"""
    if len(df) == 0:
        raise ValueError("adjust_price: Empty DataFrame")
    
    df = df.reset_index(drop=True)
    
    # 첫날 종가를 정규화 기준으로 사용
    fd_close = abs(df.at[0, "close"])
    if df.at[0, "close"] == 0.0 or pd.isna(df.at[0, "close"]):
        raise ValueError("adjust_price: First day close is nan or zero")
    
    res_df = df.copy()
    
    # 첫날 가격들을 1.0 기준으로 정규화
    res_df.at[0, "close"] = 1.0
    res_df.at[0, "open"] = abs(res_df.at[0, "open"]) / fd_close
    res_df.at[0, "high"] = abs(res_df.at[0, "high"]) / fd_close
    res_df.at[0, "low"] = abs(res_df.at[0, "low"]) / fd_close
    
    # 수익률을 사용하여 가격 재구성 (intraday 패턴 보존)
    pre_close = 1
    for i in range(1, len(res_df)):
        today_ret = np.float64(res_df.at[i, "ret"])
        today_closep = abs(res_df.at[i, "close"])
        
        # 새로운 종가 계산: (1 + 수익률) × 이전 종가
        res_df.at[i, "close"] = (1 + today_ret) * pre_close
        
        # 다른 가격들은 비례적으로 조정하여 intraday 패턴 보존
        if today_closep != 0:
            res_df.at[i, "open"] = res_df.at[i, "close"] / today_closep * abs(res_df.at[i, "open"])
            res_df.at[i, "high"] = res_df.at[i, "close"] / today_closep * abs(res_df.at[i, "high"])
            res_df.at[i, "low"] = res_df.at[i, "close"] / today_closep * abs(res_df.at[i, "low"])
        
        pre_close = res_df.at[i, "close"]
    
    return res_df

# ✅ 핵심 차이점 해결:
# - Min-Max 정규화 완전 제거
# - 첫날 종가=1.0 기준점 설정
# - 수익률 기반 순차 재구성으로 일관된 스케일링
```

### C. chart_library.py의 DrawOHLC 클래스 - ✅ 완료 (2025-01-12)
```python
# ✅ dataset.py에 generate_chart_image_pil() 함수로 완전 구현됨
def generate_chart_image_pil(price_slice, volume_slice, image_size, lookback):
    """PIL 기반 차트 이미지 생성 (chart_library.py DrawOHLC 방식)"""
    
    # ✅ 가격 범위 계산 및 유효성 검증
    all_prices = np.concatenate([...])
    minp, maxp = np.min(all_prices), np.max(all_prices)
    
    # ✅ 좌표 변환 함수 (chart_library.py의 __ret_to_yaxis와 동일)
    def ret_to_yaxis(ret):
        pixels_per_unit = (ohlc_height - 1.0) / (maxp - minp)
        res = np.around((ret - minp) * pixels_per_unit)
        return int(res)
    
    # ✅ PIL 이미지 생성 (흑백, 검은 배경)
    ohlc = Image.new("L", (ohlc_width, ohlc_height), 0)
    pixels = ohlc.load()
    
    # ✅ 이동평균선 먼저 그리기 (배경)
    if 'ma' in price_slice.columns:
        draw = ImageDraw.Draw(ohlc)
        for day in range(lookback - 1):
            # 연속된 MA 포인트를 선으로 연결
            draw.line((centers[day], ret_to_yaxis(ma_today), 
                      centers[day + 1], ret_to_yaxis(ma_next)), 
                     width=1, fill=255)
    
    # ✅ OHLC 바 그리기 (각 날짜별)
    for day in range(lookback):
        # High-Low 수직 바 (굵게)
        for x in range(left, right + 1):
            for y in range(line_bottom, line_top + 1):
                pixels[x, y] = 255  # 흰색
        
        # Open 가격 (왼쪽 수평선)
        for x in range(left, center_x + 1):
            pixels[x, open_y] = 255
        
        # Close 가격 (오른쪽 수평선)
        for x in range(center_x, right + 1):
            pixels[x, close_y] = 255
    
    # ✅ 거래량 바 추가 (하단 영역)
    if volume_height > 0:
        volume_bar = Image.new("L", (ohlc_width, volume_height), 0)
        # 거래량을 아래에서 위로 그리기
        combined = Image.new("L", (ohlc_width, total_height), 0)
        combined.paste(ohlc, (0, volume_height))  # OHLC 상단
        combined.paste(volume_bar, (0, 0))  # 거래량 하단
        final_image = combined
    else:
        final_image = ohlc
    
    # ✅ 핵심! Y축 뒤집기 (chart_library.py Line 208과 동일)
    final_image = final_image.transpose(Image.FLIP_TOP_BOTTOM)
    
    return final_image

# ✅ 주요 구현 완료:
# - PIL 기반 이미지 생성 (NumPy 직접 조작 대신)
# - 정확한 좌표 변환 (chart_library.py와 동일한 공식)
# - High-Low 바 굵게 그리기
# - Open/Close 수평선 구현
# - 이동평균선 연속 선으로 그리기
# - 최종 Y축 뒤집기 적용
```

### D. chart_dataset.py의 필터링 로직들 - ⏳ 나중에 구현 (포트폴리오 단계에서)
```python
# ⏳ 이 필터링들은 백테스팅/포트폴리오 단계에서 구현 예정
# t-통계량 필터링
if tstat_threshold != 0:
    tstats = np.divide(
        self.label_dict[self.ret_val_name], np.sqrt(self.label_dict["EWMA_vol"])
    )
    tstats = np.abs(tstats)
    t_th = np.nanpercentile(tstats[idx], tstat_threshold)
    tstat_idx = tstats > t_th
    idx = idx & tstat_idx

# 연말 데이터 제거 (look-ahead bias 방지)  
if remove_tail:
    last_day = "12/24" if self.pw == 5 else "12/1" if self.pw == 20 else "10/1"
    last_day = pd.Timestamp("{}/{}".format(last_day, self.year))
    idx = idx & (pd.to_datetime([str(t) for t in self.label_dict["Date"]]) < last_day)
```

## 🛠️ 4. 구체적 수정 순서 - 업데이트된 진행 현황

### Phase 1: 데이터 통합 - ✅ 완료 (2025-01-12)
```python  
# ✅ datageneration.ipynb에서 완료됨
# 1. WRDS에서 1992-2019 통합 데이터 다운로드 ✅
# 2. equity_data.py 방식 전처리 완료 ✅
# 3. EWMA 변동성 연속 계산 완료 ✅
# 4. 누적 로그 수익률 기반 미래 수익률 계산 완료 ✅
# 5. data_1992_2019_unified.parquet 저장 완료 ✅
```

**✅ 해결된 주요 사항:**
- 데이터 연속성 문제 해결 (1992년부터)
- equity_data.py 동일한 전처리 로직 적용
- CRSP 데이터 품질 개선 (무효값 제거)
- EDA 분석으로 데이터 검증
    return full_df
```

### Phase 2: 차트 생성 로직 교체 (2일)
```python
# dataset.py 대체
from trend_submit_integration import TrendSubmitChartGenerator

class TrendSubmitCompatibleDataset:
    def __init__(self, win_size, mode, label):
        self.full_df = pd.read_parquet('data_1993_2019_unified_trend_submit.parquet')
        self.chart_generator = TrendSubmitChartGenerator()
        
        # 모드별 타겟 년도 설정 (차트 생성은 전체 데이터 사용)
        if mode == 'train':
            self.target_years = range(1993, 2001)
        else:
            self.target_years = range(2001, 2020)
    
    def generate_images(self, sample_rate):
        results = []
        for year in self.target_years:
            year_results = self.chart_generator.generate_year_charts(
                self.full_df, year, win_size, sample_rate
            )
            results.extend(year_results)
        return results

# trend_submit_integration.py (새 파일)
class TrendSubmitChartGenerator:
    def __init__(self):
        # trend_submit의 GenerateStockData와 DrawOHLC 통합
        pass
    
    def generate_year_charts(self, full_df, year, window_size, sample_rate):
        # trend_submit의 generate_chart.py 로직 적용
        # adjust_price() 사용
        # DrawOHLC 클래스로 차트 생성
        pass
```

### Phase 3: 필터링 로직 추가 (1일)
```python
# dataset.py에 trend_submit 필터링 추가
def apply_trend_submit_filters(self, data, tstat_threshold=20, remove_tail=True):
    # 1. t-통계량 필터링
    if tstat_threshold > 0:
        tstats = np.abs(data['ret'] / np.sqrt(data['EWMA_vol']))
        t_th = np.nanpercentile(tstats, tstat_threshold)
        data = data[tstats > t_th]
    
    # 2. 연말 데이터 제거
    if remove_tail:
        data['month'] = pd.to_datetime(data['Date']).dt.month
        data = data[data['month'] <= 11]  # 12월 제거
    
    # 3. 결측치 엄격 처리
    data = data.dropna(subset=['Open', 'High', 'Low', 'Close', 'EWMA_vol'])
    
    return data
```

### Phase 4: PyTorch 통합 수정 (0.5일)
```python
def __getitem__(self, idx):
    # trend_submit 형식으로 반환
    sample = {
        "image": self.images[idx],
        "label": self.labels[idx],
        "ret_val": self.ret_vals[idx],
        "ending_date": self.dates[idx],
        "StockID": self.stock_ids[idx],
        "MarketCap": self.market_caps[idx],
    }
    return sample
```

## 🎯 5. 예상 결과

### 수정 전 (현재):
- Sharpe Ratio: -1.93 (논문과 반대 방향)
- 이미지가 논문 저자와 완전히 다름
- 데이터 품질 문제

### 수정 후 (예상):
- Sharpe Ratio: +1.5 ~ +2.5 (논문 수준)  
- 이미지가 논문 저자와 동일
- 데이터 품질 및 필터링 개선

## ✅ 6. 체크포인트

### Phase 1 완료 확인:
- [ ] 통합 파케이 파일 생성됨
- [ ] EWMA_vol이 trend_submit과 동일하게 계산됨
- [ ] 2001년 차트 생성 시 2000년 데이터 사용 가능

### Phase 2 완료 확인:
- [ ] 동일 주식/날짜에서 trend_submit과 동일한 이미지 생성
- [ ] adjust_price() 함수가 올바르게 작동
- [ ] Y축 뒤집기가 정확히 적용됨

### Phase 3 완료 확인:
- [ ] t-통계량 필터로 샘플 수 감소
- [ ] 연말 데이터 제거로 look-ahead bias 방지
- [ ] 결측치 엄격 처리로 데이터 품질 향상

### Phase 4 완료 확인:
- [ ] PyTorch 로더가 trend_submit 형식 반환
- [ ] 훈련 파이프라인이 정상 작동
- [ ] 백테스팅 결과가 논문 수준 달성

## 🔧 7. 데이터 구조 및 라벨링 호환성 분석

### A. datageneration.ipynb vs equity_data.py 호환성 - ✅ 완료
**✅ 데이터 구조 일치:**
```python
# datageneration.ipynb에서 생성된 컬럼들:
- 'code', 'date', 'close', 'volume', 'ret', 'open', 'high', 'low'
- 'mktcap', 'ewma_vol', 'ret5', 'ret20', 'ret60' 
- 'label_5', 'label_20', 'label_60'

# trend_submit equity_data.py 예상 컬럼들:
- 'StockID', 'Date', 'Close', 'Vol', 'Ret', 'Open', 'High', 'Low'
- 'MarketCap', 'EWMA_vol', 'Ret_5d', 'Ret_20d', 'Ret_60d'
```

**✅ 완전 호환 달성:**
- datageneration.ipynb에서 equity_data.py 방식으로 전처리 적용
- 동일한 EWMA 변동성 계산: `(x**2).ewm(alpha=0.05).mean().shift(periods=1)`
- 동일한 누적 로그 수익률 기반 미래 수익률: `np.exp(x.shift(-i) - x) - 1`

### B. dataset.py vs chart_dataset.py 호환성 분석

**🔍 chart_dataset.py의 핵심 구조:**
```python
# chart_dataset.py EquityDataset.__getitem__():
sample = {
    "image": image,                                    # 정규화된 차트 이미지
    "label": self.label[idx],                         # 타겟 라벨 (0/1)
    "ret_val": self.label_dict[self.ret_val_name][idx], # 실제 수익률
    "ending_date": self.label_dict["Date"][idx],       # 날짜
    "StockID": self.label_dict["StockID"][idx],        # 종목 코드
    "MarketCap": self.label_dict["MarketCap"][idx],    # 시가총액
}
```

**✅ dataset.py에서 호환성 확보:**
```python
# dataset.py single_symbol_image() 반환 구조:
entry = [image, label_ret5, label_ret20, label_ret60, 
         actual_ret5, actual_ret20, actual_ret60, 
         entry_date, entry_code, market_cap, ewma_vol]

# ✅ 필요 정보 모두 포함:
# - image: 차트 이미지 (PIL/NumPy 생성)
# - label_ret5/20/60: 바이너리 라벨 (0/1)
# - actual_ret5/20/60: 실제 수익률 (백분율)
# - entry_date, entry_code: 메타데이터
# - market_cap, ewma_vol: 추가 피처
```

### C. 이미지 데이터 형식 호환성

**🔍 trend_submit 이미지 저장 방식:**
```python
# chart_dataset.py에서 로딩:
images = np.memmap(images_path, dtype=np.uint8, mode="r")
images = images.reshape((-1, height, width))

# 이미지 정규화:
image = (self.images[idx] / 255.0 - self.demean[0]) / self.demean[1]
```

**✅ dataset.py 호환성:**
```python
# ✅ 동일한 uint8 형식으로 이미지 생성
# ✅ 0-255 픽셀 값 범위 사용 (0=검은 배경, 255=흰 선)
# ✅ PIL 이미지를 numpy 배열로 변환: np.array(image_pil)
# ✅ 최종 shape: (height, width) - 단일 채널 grayscale
```

### D. 라벨명 변경 사항 및 호환성

**⚠️ 잠재적 호환성 이슈 발견:**
```python
# datageneration.ipynb에서 생성된 라벨명:
'label_5', 'label_20', 'label_60'  # 바이너리 (0/1)
'ret5', 'ret20', 'ret60'           # 백분율 수익률

# dataset.py에서 사용하는 라벨명:
tabular_df.iloc[d]['label_5']      # ✅ 일치
tabular_df.iloc[d]['ret5']         # ✅ 일치

# chart_dataset.py에서 기대하는 라벨명:
self.label_dict["Ret_5d"]          # ❌ 불일치!
self.label_dict[f"Ret_{self.pw}d"] # ❌ 형식 다름
```

**✅ 해결 방안:**
- datageneration.ipynb에서 이미 호환 라벨 생성: `ret5`, `ret20`, `ret60`
- dataset.py에서 정확한 컬럼명 사용 중
- 필요시 추가 컬럼명 매핑 가능

## ✅ 8. 차트 생성 파일 구조 완전 개선 (2025-01-12 완료)

### A. 파일 구조 정리 완료
**✅ 최종 구조 (trend_submit과 동일):**
```
data/
├── chart_library.py              # DrawOHLC 클래스만 (깔끔한 분리)
├── chart_generator.py            # 메인 생성 스크립트 + adjust_price
├── chart_image_generation.ipynb  # 이미지 생성 실행 노트북 (이름 변경)
├── data_processing_and_unification.ipynb  # 데이터 전처리 노트북 (이름 변경)
└── data_1992_2019_unified.parquet         # 통합 데이터
```

### B. 완료된 수정 사항
1. **✅ 불필요한 파일 삭제:**
   - stock_data_processor.py (삭제 완료)
   - chart_image_generator.py (삭제 완료)

2. **✅ 파일명 기능별 변경:**
   - 1_image_generation.ipynb → chart_image_generation.ipynb
   - datageneration.ipynb → data_processing_and_unification.ipynb

3. **✅ 노트북 스크립트 호출 수정:**
   ```python
   # 기존 (틀림):
   !python ../datageneration.py --image_days 5 --mode train
   
   # 수정 완료:
   !python chart_generator.py --image_days 5 --mode train
   ```

4. **✅ 파일 분리 구조 완성:**
   - chart_library.py: DrawOHLC 클래스만 (trend_submit과 동일)
   - chart_generator.py: 메인 로직 + adjust_price (trend_submit과 동일)

### C. 현재 상태
**🎉 파일 구조 개선 100% 완료**
- ✅ 모든 불필요 파일 정리
- ✅ 기능별 명확한 파일명 적용  
- ✅ trend_submit과 동일한 분리 구조
- ✅ 노트북에서 올바른 스크립트 호출

### D. 다음 단계
**⏳ 실행 테스트만 남음:**
1. chart_image_generation.ipynb 실행
2. 새로운 파일 구조로 이미지 생성 검증
3. 생성된 이미지 품질 확인

**핵심: 파일 구조 개선 완전히 완료, 이제 실행 테스트 단계**

## 🚀 9. 통합 캘린더 샘플링 구현 상세 (2025-01-13)

### A. 기존 문제점 및 해결책
**🚨 기존 문제 (개별 주식 윈도우):**
```python
# 각 주식마다 독립적인 윈도우 생성
for stock_code, stock_df in df.groupby('code'):
    for d in range(lookback-1, len(stock_df), lookback):
        # 문제: 주식마다 다른 날짜 윈도우 사용 → 231개 서로 다른 날짜
```

**✅ 해결책 (통합 캘린더 윈도우):**
```python
# 전체 거래일 기준 통합 윈도우
all_dates = sorted(df['date'].unique())  # 2020개 거래일
window_indices = range(lookback-1, len(all_dates), lookback)  # 101개 윈도우

for stock_code, stock_df in tqdm(stock_groups):
    for start_idx in window_indices:
        window_dates = all_dates[start_idx-(lookback-1):start_idx+1]
        # 모든 주식이 동일한 20일 윈도우 사용
```

### B. 현실성 및 실용성 개선
**🎯 현실적 리밸런싱 구현:**
- ✅ 모든 주식이 동일한 20일 간격으로 평가됨
- ✅ 포트폴리오 매니저가 실제로 사용할 수 있는 일관된 리밸런싱 스케줄
- ✅ 101개 리밸런싱 날짜 = 연평균 12.6회 리밸런싱 (현실적)

**📊 데이터 독립성:**
- ✅ Non-overlapping 윈도우로 데이터 누출 방지
- ✅ Train/Test 분할에서 시간적 독립성 확보
- ✅ 백테스팅에서 Look-ahead bias 방지

### C. 성능 최적화 결과
**⚡ 처리 속도 개선:**
```python
# 🚨 기존 (느림): 101 × 11,752 = 118만 번 필터링
for start_idx in range(...):        # 101개 윈도우
    for stock_code in df['code'].unique():  # 11,752 주식
        stock_df = df[df['code'] == stock_code].copy()  # 매번 필터링!

# ✅ 개선 (빠름): 11,752 × 101 = 동일하지만 사전 그룹핑
stock_groups = df.groupby('code')    # 1회만 그룹핑
for stock_code, stock_df in tqdm(stock_groups):  # 11,752 주식
    for start_idx in window_indices:  # 101 윈도우 (필터링 없음)
```

**📈 진행률 모니터링:**
- ✅ tqdm 프로그레스바 복구: `Processing stocks: 10% 1202/11752 [12:17<2:20:14, 1.25it/s]`
- ✅ 예상 완료 시간: 2시간 20분
- ✅ 실시간 처리 상태 확인 가능

### D. 메모리 효율성 검증
**💾 메모리 사용 패턴:**
- ✅ 전체 이미지를 메모리에 누적 (최대 몇 GB)
- ✅ 년도별 분류 저장으로 호환성 유지
- ✅ 중간 실패 시에도 부분 결과 확인 가능

**🔄 저장 방식:**
```python
# 1. 전체 처리 완료 후 년도별 분류
dates_df = pd.DataFrame({'date': dates, 'image_idx': range(len(dates))})
dates_df['year'] = pd.to_datetime(dates_df['date'], format='%Y%m%d').dt.year

# 2. 년도별 파일 저장 (기존 형식 유지)
for year in [1993, 1994, ..., 2000]:
    year_data = dates_df[dates_df['year'] == year]
    save_images_and_labels(year_images, year_labels, year, ...)
```

## 🎯 10. 다음 단계 및 예상 결과

### A. 현재 진행 중 작업
**🔄 진행 중:**
- chart_generator.py --image_days 20 --mode train 실행 중
- 11,752 주식 중 1,202개 완료 (10%)
- 예상 완료: 2시간 후

### B. 완료 후 검증 계획
**✅ 데이터 품질 검증:**
1. 생성된 총 이미지 수 확인 (예상: 수만 개)
2. 년도별 분포 확인 (1993-2000년 각각)
3. 샘플 이미지 시각적 검증

**✅ 성능 테스트:**
1. 5일, 60일 윈도우도 동일 방식으로 생성
2. train.py로 CNN 모델 훈련
3. Sharpe ratio 개선 여부 확인 (-1.93 → +2.16 목표)

### C. 예상 개선 효과
**📈 성능 개선 예상:**
- ✅ 통합 캘린더 → 현실적 백테스팅 환경
- ✅ Non-overlapping → 데이터 독립성 확보  
- ✅ 일관된 리밸런싱 → 포트폴리오 전략 개선
- ✅ trend_submit 방식 접근 → 논문 수준 성능 기대