{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Re-Imaging Price Trends - Image Generation\n",
        "\n",
        "**Purpose**: Convert stock price data to candlestick chart images and save to disk\n",
        "\n",
        "**Next Step**: Run `2_model_training.ipynb` after completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"File list: {[f for f in os.listdir('.') if not f.startswith('.')]}\")\n",
        "\n",
        "# Check Numba JIT performance optimization\n",
        "try:\n",
        "    import numba\n",
        "    print(f\"Numba JIT available: {numba.__version__}\")\n",
        "    print(\"   Image generation speed improved by 50-100x!\")\n",
        "except ImportError:\n",
        "    print(\"Numba installation failed - check requirements.txt\")\n",
        "\n",
        "# Check memory status\n",
        "import psutil\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"Available memory: {memory.available // (1024**3):.1f}GB\")\n",
        "if memory.available < 2 * (1024**3):  # Less than 2GB\n",
        "    print(\"Warning: Low memory - recommend using --parallel 1 option\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# 환경 설정 및 최적화 확인\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_data"
      },
      "outputs": [],
      "source": [
        "# Check data files (both original and filled versions)\n",
        "data_files = [\n",
        "    'data/data_1993_2000_train_val.parquet',\n",
        "    'data/data_2001_2019_test.parquet',\n",
        "    'data/data_1993_2000_train_val_filled.parquet',\n",
        "    'data/data_2001_2019_test_filled.parquet'\n",
        "]\n",
        "\n",
        "print(\"Data file check:\")\n",
        "print(\"Original data files:\")\n",
        "original_exist = True\n",
        "for file in data_files[:2]:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024**2)\n",
        "        print(f\"✓ {file} ({size_mb:.1f}MB)\")\n",
        "    else:\n",
        "        print(f\"✗ {file} missing\")\n",
        "        original_exist = False\n",
        "\n",
        "print(\"\\nFilled data files:\")\n",
        "filled_exist = True        \n",
        "for file in data_files[2:]:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024**2)\n",
        "        print(f\"✓ {file} ({size_mb:.1f}MB)\")\n",
        "    else:\n",
        "        print(f\"✗ {file} missing\")\n",
        "        filled_exist = False\n",
        "\n",
        "print(f\"\\nData availability:\")\n",
        "print(f\"   Original data: {'✓ Available' if original_exist else '✗ Missing'}\")\n",
        "print(f\"   Filled data: {'✓ Available' if filled_exist else '✗ Missing'}\")\n",
        "\n",
        "if not original_exist and not filled_exist:\n",
        "    print(\"\\nWarning: No data files found. Run data/datageneration.ipynb first.\")\n",
        "elif not filled_exist:\n",
        "    print(\"\\nNote: Only original data available. Run data_preprocessing_filled.ipynb to create filled data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "original_header"
      },
      "source": [
        "## Original Data Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_5d_train"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 5 --mode train --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_5d_test"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 5 --mode test --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_20d_train"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 20 --mode train --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_20d_test"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 20 --mode test --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_60d_train"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 60 --mode train --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "original_60d_test"
      },
      "outputs": [],
      "source": [
        "!python datageneration.py --image_days 60 --mode test --sample_rate 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_original_results"
      },
      "outputs": [],
      "source": [
        "# Check generated original format images\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "print(\"Generated original format image summary:\")\n",
        "\n",
        "# Check original format directories\n",
        "original_dirs = {\n",
        "    'weekly_5d': (5, '5d_week_has_vb_[5]_ma'),\n",
        "    'monthly_20d': (20, '20d_month_has_vb_[20]_ma'),\n",
        "    'quarterly_60d': (60, '60d_quarter_has_vb_[60]_ma')\n",
        "}\n",
        "\n",
        "base_dir = 'img_data_reconstructed'\n",
        "if os.path.exists(base_dir):\n",
        "    total_images = 0\n",
        "    total_size_gb = 0\n",
        "    success_count = 0\n",
        "\n",
        "    for dir_name, (win_size, prefix) in original_dirs.items():\n",
        "        img_dir = os.path.join(base_dir, dir_name)\n",
        "\n",
        "        if os.path.exists(img_dir):\n",
        "            # Check .dat and .feather files\n",
        "            dat_files = [f for f in os.listdir(img_dir) if f.endswith('.dat')]\n",
        "            feather_files = [f for f in os.listdir(img_dir) if f.endswith('.feather')]\n",
        "\n",
        "            dir_images = 0\n",
        "            dir_size = 0\n",
        "\n",
        "            # Check files for each year\n",
        "            for dat_file in dat_files:\n",
        "                dat_path = os.path.join(img_dir, dat_file)\n",
        "\n",
        "                # Calculate image count (based on .dat file size)\n",
        "                file_size = os.path.getsize(dat_path)\n",
        "                if win_size == 5:\n",
        "                    image_size = 32 * 15  # 5-day: 32x15\n",
        "                elif win_size == 20:\n",
        "                    image_size = 64 * 60  # 20-day: 64x60\n",
        "                else:  # 60\n",
        "                    image_size = 96 * 180  # 60-day: 96x180\n",
        "\n",
        "                num_images = file_size // image_size\n",
        "                dir_images += num_images\n",
        "                dir_size += file_size\n",
        "\n",
        "            # Add .feather file sizes\n",
        "            for feather_file in feather_files:\n",
        "                feather_path = os.path.join(img_dir, feather_file)\n",
        "                dir_size += os.path.getsize(feather_path)\n",
        "\n",
        "            size_gb = dir_size / (1024**3)\n",
        "            total_size_gb += size_gb\n",
        "\n",
        "            print(f\"✓ {dir_name}: {dir_images:,} images, {size_gb:.2f}GB\")\n",
        "            print(f\"   .dat files: {len(dat_files)}, .feather files: {len(feather_files)}\")\n",
        "\n",
        "            total_images += dir_images\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"✗ {dir_name}: not generated\")\n",
        "\n",
        "    print(f\"\\nOriginal data results:\")\n",
        "    print(f\"   Success: {success_count}/{len(original_dirs)} directories\")\n",
        "    print(f\"   Total images: {total_images:,}\")\n",
        "    print(f\"   Total size: {total_size_gb:.2f}GB\")\n",
        "    print(f\"   Average size per image: {total_size_gb*1024*1024/max(total_images,1):.1f}KB\")\n",
        "\n",
        "    if success_count == len(original_dirs):\n",
        "        print(f\"\\n✅ All original format images generated successfully!\")\n",
        "        print(f\"Save path: {base_dir}/\")\n",
        "        print(f\"Format: .dat (binary images) + .feather (labels)\")\n",
        "        print(f\"\\nSaved in same format as original paper authors\")\n",
        "    else:\n",
        "        print(f\"\\nWarning: {len(original_dirs)-success_count} directories failed\")\n",
        "        print(\"   Check datageneration.py error logs.\")\n",
        "else:\n",
        "    print(f\"✗ {base_dir} directory not created.\")\n",
        "    print(\"   Check datageneration.py execution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filled_header"
      },
      "source": [
        "## Filled Data Image Generation (Missing Values Filled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_5d_train"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 5-day images for training data (filled version)...\")\n",
        "!python datageneration.py --image_days 5 --mode train --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_5d_test"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 5-day images for test data (filled version)...\")\n",
        "!python datageneration.py --image_days 5 --mode test --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_20d_train"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 20-day images for training data (filled version)...\")\n",
        "!python datageneration.py --image_days 20 --mode train --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_20d_test"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 20-day images for test data (filled version)...\")\n",
        "!python datageneration.py --image_days 20 --mode test --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_60d_train"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 60-day images for training data (filled version)...\")\n",
        "!python datageneration.py --image_days 60 --mode train --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filled_60d_test"
      },
      "outputs": [],
      "source": [
        "print(f\"Generating 60-day images for test data (filled version)...\")\n",
        "!python datageneration.py --image_days 60 --mode test --sample_rate 1.0 --data_version filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_filled_results"
      },
      "outputs": [],
      "source": [
        "# Check generated filled format images\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "print(\"Generated filled format image summary:\")\n",
        "\n",
        "# Check filled format directories\n",
        "filled_dirs = {\n",
        "    'weekly_5d': (5, '5d_week_has_vb_[5]_ma'),\n",
        "    'monthly_20d': (20, '20d_month_has_vb_[20]_ma'),\n",
        "    'quarterly_60d': (60, '60d_quarter_has_vb_[60]_ma')\n",
        "}\n",
        "\n",
        "base_dir = 'img_data_reconstructed_filled'\n",
        "if os.path.exists(base_dir):\n",
        "    total_images = 0\n",
        "    total_size_gb = 0\n",
        "    success_count = 0\n",
        "\n",
        "    for dir_name, (win_size, prefix) in filled_dirs.items():\n",
        "        img_dir = os.path.join(base_dir, dir_name)\n",
        "\n",
        "        if os.path.exists(img_dir):\n",
        "            # Check .dat and .feather files\n",
        "            dat_files = [f for f in os.listdir(img_dir) if f.endswith('.dat')]\n",
        "            feather_files = [f for f in os.listdir(img_dir) if f.endswith('.feather')]\n",
        "\n",
        "            dir_images = 0\n",
        "            dir_size = 0\n",
        "\n",
        "            # Check files for each year\n",
        "            for dat_file in dat_files:\n",
        "                dat_path = os.path.join(img_dir, dat_file)\n",
        "\n",
        "                # Calculate image count (based on .dat file size)\n",
        "                file_size = os.path.getsize(dat_path)\n",
        "                if win_size == 5:\n",
        "                    image_size = 32 * 15  # 5-day: 32x15\n",
        "                elif win_size == 20:\n",
        "                    image_size = 64 * 60  # 20-day: 64x60\n",
        "                else:  # 60\n",
        "                    image_size = 96 * 180  # 60-day: 96x180\n",
        "\n",
        "                num_images = file_size // image_size\n",
        "                dir_images += num_images\n",
        "                dir_size += file_size\n",
        "\n",
        "            # Add .feather file sizes\n",
        "            for feather_file in feather_files:\n",
        "                feather_path = os.path.join(img_dir, feather_file)\n",
        "                dir_size += os.path.getsize(feather_path)\n",
        "\n",
        "            size_gb = dir_size / (1024**3)\n",
        "            total_size_gb += size_gb\n",
        "\n",
        "            print(f\"✓ {dir_name}: {dir_images:,} images, {size_gb:.2f}GB\")\n",
        "            print(f\"   .dat files: {len(dat_files)}, .feather files: {len(feather_files)}\")\n",
        "\n",
        "            total_images += dir_images\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"✗ {dir_name}: not generated\")\n",
        "\n",
        "    print(f\"\\nFilled data results:\")\n",
        "    print(f\"   Success: {success_count}/{len(filled_dirs)} directories\")\n",
        "    print(f\"   Total images: {total_images:,}\")\n",
        "    print(f\"   Total size: {total_size_gb:.2f}GB\")\n",
        "    print(f\"   Average size per image: {total_size_gb*1024*1024/max(total_images,1):.1f}KB\")\n",
        "\n",
        "    if success_count == len(filled_dirs):\n",
        "        print(f\"\\n✅ All filled format images generated successfully!\")\n",
        "        print(f\"Save path: {base_dir}/\")\n",
        "        print(f\"Format: .dat (binary images) + .feather (labels)\")\n",
        "        print(f\"\\nFilled data: Missing values replaced with previous close prices\")\n",
        "        print(f\"This should provide more complete training data with fewer gaps\")\n",
        "    else:\n",
        "        print(f\"\\nWarning: {len(filled_dirs)-success_count} directories failed\")\n",
        "        print(\"   Check datageneration.py error logs.\")\n",
        "\n",
        "    # Compare with original if exists\n",
        "    original_base_dir = 'img_data_reconstructed'\n",
        "    if os.path.exists(original_base_dir):\n",
        "        print(f\"\\n📊 Comparison with original data:\")\n",
        "        print(f\"   Original: {original_base_dir}/\")\n",
        "        print(f\"   Filled: {base_dir}/\")\n",
        "        print(f\"   Filled data should have equal or more images due to fewer NA gaps\")\n",
        "else:\n",
        "    print(f\"✗ {base_dir} directory not created.\")\n",
        "    print(\"   Check datageneration.py execution with --data_version filled.\")"
      ]
    }
  ]
}