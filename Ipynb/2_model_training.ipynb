{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": "# Re-Imaging Price Trends - Model Training & Evaluation\n\n**Prerequisites**: `1_image_generation.ipynb` completed\n\n**Execution**: CNN model training → Portfolio performance evaluation → Result visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": "# Environment setup\n!pip install -r requirements.txt\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nos.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\nprint(f\"Current directory: {os.getcwd()}\")\n\n# GPU check\nimport torch\nprint(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n\n# GPU memory monitoring and management functions\ndef check_gpu_memory():\n    \"\"\"Check and display GPU memory status\"\"\"\n    if torch.cuda.is_available():\n        device = torch.cuda.current_device()\n        total_memory = torch.cuda.get_device_properties(device).total_memory\n        allocated = torch.cuda.memory_allocated(device)\n        cached = torch.cuda.memory_reserved(device)\n        \n        print(f\"GPU memory status:\")\n        print(f\"   Total: {total_memory/1024**3:.1f}GB\")\n        print(f\"   Used: {allocated/1024**3:.1f}GB ({allocated/total_memory*100:.1f}%)\")\n        print(f\"   Cached: {cached/1024**3:.1f}GB ({cached/total_memory*100:.1f}%)\")\n        print(f\"   Available: {(total_memory-allocated)/1024**3:.1f}GB\")\n        \n        return allocated, total_memory\n    else:\n        print(\"GPU unavailable - CPU mode\")\n        return 0, 0\n\ndef cleanup_memory():\n    \"\"\"Memory cleanup and garbage collection\"\"\"\n    import gc\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n    gc.collect()\n    print(\"Memory cleanup completed\")\n\n# Check initial GPU memory status\nprint(\"Initial GPU memory status:\")\ncheck_gpu_memory()\ncleanup_memory()"
  },
  {
   "cell_type": "code",
   "source": "# Check original format images (img_data_reconstructed)\nimport os\n\n# Use absolute path for Colab environment\nbase_path = '/content/drive/MyDrive/ReImaging_Price_Trends' if 'google.colab' in str(get_ipython()) else '.'\noriginal_data_dir = os.path.join(base_path, 'img_data_reconstructed')\n\nprint(f\"Original data path: {original_data_dir}\")\n\n# Check original format (.dat + .feather) directories\nrequired_dirs = {\n    '5d (weekly)': 'weekly_5d',\n    '20d (monthly)': 'monthly_20d', \n    '60d (quarterly)': 'quarterly_60d'\n}\n\nall_ready = True\nfor desc, dir_name in required_dirs.items():\n    dir_path = os.path.join(original_data_dir, dir_name)\n    if os.path.exists(dir_path):\n        # Check a few year files as examples\n        sample_files = [f for f in os.listdir(dir_path) if f.endswith('.dat')][:3]\n        print(f\"✓ {desc}: {len(sample_files)} year files (examples)\")\n        for f in sample_files:\n            print(f\"   - {f}\")\n    else:\n        print(f\"✗ {desc}: {dir_path}\")\n        all_ready = False\n\nif all_ready:\n    print(f\"\\nOriginal format data ready!\")\n    print(\"   Same .dat + .feather format as paper authors\")\n    print(\"   Will be executed with --use_original_format flag\")\nelse:\n    print(f\"\\nWarning: Some original data missing\")\n    print(\"Generate with create_original_format.py or use HDF5 format\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_header"
   },
   "source": "## CNN Model Training (Paper-style Ensemble Support)\n\n**Format Used**: `.dat` + `.feather` (same as paper authors)  \n**Data Location**: `img_data_reconstructed/`  \n**Ensemble**: Paper-mentioned 5-model averaging supported  \n\n### Training Method Selection:\n1. **Single Model**: Fast testing\n2. **Ensemble Model**: Same as paper with 5-model averaging (more stable)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn5d"
   },
   "outputs": [],
   "source": "# CNN5d model training selection\n\nprint(\"CNN5d training method selection:\")\nprint(\"   Single model: Fast (1 model)\")\nprint(\"   Ensemble: Paper method (5-model average)\")\n\n# Training method setting (changeable)\nuse_ensemble = False  # Change to True for ensemble training\n\nprint(\"GPU memory status (before training):\")\ncheck_gpu_memory()\n\nif use_ensemble:\n    print(\"\\nCNN5d ensemble training (5 models)...\")\n    print(\"Warning: Takes 5x longer!\")\n    !python ensemble_train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble_runs 5 --use_original_format\nelse:\n    print(\"\\nCNN5d single model training...\")\n    !python train.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\n\nprint(\"\\nGPU memory status (after training):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"CNN5d training completed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn20d"
   },
   "outputs": [],
   "source": "# CNN20d model training selection\n\nprint(\"CNN20d training method selection:\")\nprint(\"   Single model: Fast (1 model)\")\nprint(\"   Ensemble: Paper method (5-model average)\")\n\n# Training method setting (changeable)\nuse_ensemble = False  # Change to True for ensemble training\n\nprint(\"GPU memory status (before training):\")\ncheck_gpu_memory()\n\nif use_ensemble:\n    print(\"\\nCNN20d ensemble training (5 models)...\")\n    print(\"Warning: Takes 5x longer!\")\n    !python ensemble_train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble_runs 5 --use_original_format\nelse:\n    print(\"\\nCNN20d single model training...\")\n    !python train.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\n\nprint(\"\\nGPU memory status (after training):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"CNN20d training completed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn60d"
   },
   "outputs": [],
   "source": "# CNN60d model training selection (memory intensive)\n\nprint(\"CNN60d training method selection (Warning: Memory intensive):\")\nprint(\"   Single model: Fast (1 model)\")  \nprint(\"   Ensemble: Paper method (5-model average)\")\n\n# Training method setting (changeable)\nuse_ensemble = False  # Change to True for ensemble training\n\nprint(\"GPU memory status (before training):\")\nallocated, total = check_gpu_memory()\n\n# Memory shortage warning\nif allocated > total * 0.7:  # Warning if using more than 70%\n    print(\"Warning: GPU memory shortage risk! Performing additional cleanup...\")\n    cleanup_memory()\n\nif use_ensemble:\n    print(\"\\nCNN60d ensemble training (5 models)...\")\n    print(\"Warning: Takes 5x longer!\")\n    !python ensemble_train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble_runs 5 --use_original_format --batch_size 64\nelse:\n    print(\"\\nCNN60d single model training...\")\n    !python train.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --batch_size 64\n\nprint(\"\\nGPU memory status (after training):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"CNN60d training completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_header"
   },
   "source": "# Evaluate all models (original format)\nprint(\"Portfolio performance evaluation started (original .dat + .feather format)...\\n\")\n\nprint(\"1. CNN5d (Weekly Strategy)\")\n!python test.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\ncleanup_memory()\n\nprint(\"\\n2. CNN20d (Monthly Strategy)\")\n!python test.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\ncleanup_memory()\n\nprint(\"\\n3. CNN60d (Quarterly Strategy)\")\n!python test.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format\ncleanup_memory()\n\nprint(\"\\nAll evaluations completed!\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_models"
   },
   "outputs": [],
   "source": "# Portfolio performance evaluation (with ensemble support)\n\nprint(\"Portfolio performance evaluation started...\\n\")\nprint(\"Evaluation methods:\")\nprint(\"   Single model: Regular prediction\")\nprint(\"   Ensemble: 5-model average prediction (more stable)\")\n\n# Evaluation method setting (match with training method)\nuse_ensemble_eval = False  # Change to True if trained with ensemble\n\nprint(\"1. CNN5d (Weekly Strategy)\")\nif use_ensemble_eval:\n    !python test.py --model CNN5d --image_days 5 --pred_days 5 --ensemble --use_original_format\nelse:\n    !python test.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\ncleanup_memory()\n\nprint(\"\\n2. CNN20d (Monthly Strategy)\")\nif use_ensemble_eval:\n    !python test.py --model CNN20d --image_days 20 --pred_days 20 --ensemble --use_original_format\nelse:\n    !python test.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\ncleanup_memory()\n\nprint(\"\\n3. CNN60d (Quarterly Strategy)\")\nif use_ensemble_eval:\n    !python test.py --model CNN60d --image_days 60 --pred_days 60 --ensemble --use_original_format\nelse:\n    !python test.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format\ncleanup_memory()\n\nprint(\"\\nAll evaluations completed!\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_header"
   },
   "source": "## Result Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_training"
   },
   "outputs": [],
   "source": "# Final results summary & GPU memory analysis\nprint(\"Re-Imaging Price Trends - Execution completed!\")\nprint(\"=\" * 50)\n\n# GPU memory analysis results\nprint(\"\\nGPU memory requirements (batch size 128):\")\nprint(\"   • CNN5d:  ~0.02GB (lightest)\")\nprint(\"   • CNN20d: ~0.09GB (medium)\")  \nprint(\"   • CNN60d: ~0.34GB (heaviest)\")\nprint(\"\\nNote: Actual usage may be 2-3x higher with data loading + optimizer state\")\n\nprint(\"\\nColab GPU compatibility:\")\nprint(\"   • T4 (16GB): All models trainable\")\nprint(\"   • V100/A100: Large batch processing possible\")\nprint(\"   • CNN60d: batch size 64 recommended\")\n\n# File size summary\nif os.path.exists('models'):\n    print(\"\\nTrained models:\")\n    for file in sorted(os.listdir('models')):\n        if file.endswith('.tar'):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"   ✓ {file} ({size_mb:.1f}MB)\")\n\n# Paper performance comparison\nprint(\"\\nExpected paper performance (comparison reference):\")\nprint(\"   • Weekly (I5R5): H-L Sharpe = 7.15\")\nprint(\"   • Monthly (I20R20): H-L Sharpe = 2.16\") \nprint(\"   • Quarterly (I60R60): H-L Sharpe = 0.37\")\n\nprint(\"\\nFormat used:\")\nprint(\"   • Original format (.dat + .feather): Same as paper authors\")\nprint(\"   • Memory efficient and Colab friendly\")\n\nprint(\"\\nCompare the portfolio evaluation results above with paper benchmarks!\")\nprint(\"\\nFinal GPU memory status:\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": "# Final results summary & ensemble information\n\nprint(\"Re-Imaging Price Trends - Execution completed!\")\nprint(\"=\" * 60)\n\n# GPU memory analysis results\nprint(\"\\nGPU memory requirements (batch size 128):\")\nprint(\"   • CNN5d:  ~0.02GB (lightest)\")\nprint(\"   • CNN20d: ~0.09GB (medium)\")  \nprint(\"   • CNN60d: ~0.34GB (heaviest)\")\nprint(\"\\nNote: Actual usage may be 2-3x higher with data loading + optimizer state\")\n\nprint(\"\\nColab GPU compatibility:\")\nprint(\"   • T4 (16GB): All models trainable\")\nprint(\"   • V100/A100: Large batch processing possible\")\nprint(\"   • CNN60d: batch size 64 recommended\")\n\n# Ensemble vs single model explanation\nprint(\"\\nModel training methods:\")\nprint(\"   • Single model: Fast, for testing\")\nprint(\"   • Ensemble (5 models): Paper method, more stable performance\")\nprint(\"     - Train same model 5 times independently\")\nprint(\"     - Average 5 results during prediction\")\nprint(\"     - Reduces stochastic variability\")\n\n# File size summary\nif os.path.exists('models'):\n    print(\"\\nTrained models:\")\n    model_files = [f for f in os.listdir('models') if f.endswith('.tar')]\n    \n    # Single models\n    single_models = [f for f in model_files if '_run' not in f]\n    if single_models:\n        print(\"   Single models:\")\n        for file in sorted(single_models):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"     ✓ {file} ({size_mb:.1f}MB)\")\n    \n    # Ensemble models\n    ensemble_models = [f for f in model_files if '_run' in f]\n    if ensemble_models:\n        print(\"   Ensemble models:\")\n        for file in sorted(ensemble_models):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"     ✓ {file} ({size_mb:.1f}MB)\")\n\n# Paper performance comparison\nprint(\"\\nExpected paper performance (comparison reference):\")\nprint(\"   • Weekly (I5R5): H-L Sharpe = 7.15\")\nprint(\"   • Monthly (I20R20): H-L Sharpe = 2.16\") \nprint(\"   • Quarterly (I60R60): H-L Sharpe = 0.37\")\n\nprint(\"\\nFormat used:\")\nprint(\"   • Original format (.dat + .feather): Same as paper authors\")\nprint(\"   • Memory efficient and Colab friendly\")\n\nprint(\"\\nCheck portfolio evaluation results and compare with paper!\")\nprint(\"\\nFinal GPU memory status:\")\ncheck_gpu_memory()"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}