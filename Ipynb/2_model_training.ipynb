{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# 2️⃣ Re-Imaging Price Trends - 모델 학습 & 평가\n",
    "\n",
    "**전제조건**: `1_image_generation.ipynb` 완료\n",
    "\n",
    "**실행 내용**: CNN 모델 학습 → 포트폴리오 성과 평가 → 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": "# 환경 설정\n!pip install -r requirements.txt\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nos.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\nprint(f\"📁 현재 디렉토리: {os.getcwd()}\")\n\n# GPU 확인\nimport torch\nprint(f\"🖥️ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n\n# GPU 메모리 모니터링 및 관리 함수 정의\ndef check_gpu_memory():\n    \"\"\"GPU 메모리 상태 확인 및 출력\"\"\"\n    if torch.cuda.is_available():\n        device = torch.cuda.current_device()\n        total_memory = torch.cuda.get_device_properties(device).total_memory\n        allocated = torch.cuda.memory_allocated(device)\n        cached = torch.cuda.memory_reserved(device)\n        \n        print(f\"🖥️ GPU 메모리 상태:\")\n        print(f\"   전체: {total_memory/1024**3:.1f}GB\")\n        print(f\"   사용중: {allocated/1024**3:.1f}GB ({allocated/total_memory*100:.1f}%)\")\n        print(f\"   캐시: {cached/1024**3:.1f}GB ({cached/total_memory*100:.1f}%)\")\n        print(f\"   여유: {(total_memory-allocated)/1024**3:.1f}GB\")\n        \n        return allocated, total_memory\n    else:\n        print(\"🖥️ GPU 사용 불가 - CPU 모드\")\n        return 0, 0\n\ndef cleanup_memory():\n    \"\"\"메모리 정리 및 가비지 컬렉션\"\"\"\n    import gc\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n    gc.collect()\n    print(\"🧹 메모리 정리 완료\")\n\n# 초기 GPU 메모리 상태 확인\nprint(\"🔍 초기 GPU 메모리 상태:\")\ncheck_gpu_memory()\ncleanup_memory()"
  },
  {
   "cell_type": "code",
   "source": "# 원본 형식 이미지 확인 (img_data_reconstructed)\nimport os\n\n# Colab 환경에서의 절대경로 사용\nbase_path = '/content/drive/MyDrive/ReImaging_Price_Trends' if 'google.colab' in str(get_ipython()) else '.'\noriginal_data_dir = os.path.join(base_path, 'img_data_reconstructed')\n\nprint(f\"📁 원본 데이터 경로: {original_data_dir}\")\n\n# 원본 형식(.dat + .feather) 디렉토리 확인\nrequired_dirs = {\n    '5d (weekly)': 'weekly_5d',\n    '20d (monthly)': 'monthly_20d', \n    '60d (quarterly)': 'quarterly_60d'\n}\n\nall_ready = True\nfor desc, dir_name in required_dirs.items():\n    dir_path = os.path.join(original_data_dir, dir_name)\n    if os.path.exists(dir_path):\n        # 몇 개 연도 파일 확인\n        sample_files = [f for f in os.listdir(dir_path) if f.endswith('.dat')][:3]\n        print(f\"✅ {desc}: {len(sample_files)}개 연도 파일 예시\")\n        for f in sample_files:\n            print(f\"   - {f}\")\n    else:\n        print(f\"❌ {desc}: {dir_path}\")\n        all_ready = False\n\nif all_ready:\n    print(f\"\\n🎉 원본 형식 데이터 준비 완료!\")\n    print(\"   논문 저자와 동일한 .dat + .feather 형식 사용\")\n    print(\"   --use_original_format 플래그로 실행됩니다\")\nelse:\n    print(f\"\\n⚠️ 일부 원본 데이터가 없습니다\")\n    print(\"create_original_format.py로 생성하거나 HDF5 형식 사용하세요\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_header"
   },
   "source": "## 🧠 CNN 모델 학습 (논문 방식 앙상블 지원)\n\n**사용 형식**: `.dat` + `.feather` (논문 저자와 동일)  \n**데이터 위치**: `img_data_reconstructed/`  \n**앙상블**: 논문에서 언급한 5모델 평균 지원  \n\n### 학습 방식 선택:\n1. **단일 모델**: 빠른 테스트용\n2. **앙상블 모델**: 논문과 동일한 5모델 평균 (더 안정적)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn5d"
   },
   "outputs": [],
   "source": "# CNN5d 모델 학습 선택\n\nprint(\"🧠 CNN5d 학습 방식 선택:\")\nprint(\"   단일 모델: 빠름 (1개 모델)\")\nprint(\"   앙상블: 논문 방식 (5개 모델 평균)\")\n\n# 🔧 학습 방식 설정 (변경 가능)\nuse_ensemble = False  # True로 변경하면 앙상블 학습\n\nprint(\"GPU 메모리 상태 (학습 전):\")\ncheck_gpu_memory()\n\nif use_ensemble:\n    print(\"\\n🔥 CNN5d 앙상블 학습 (5개 모델)...\")\n    print(\"⚠️ 시간이 5배 더 걸립니다!\")\n    !python ensemble_train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble_runs 5 --use_original_format\nelse:\n    print(\"\\n🧠 CNN5d 단일 모델 학습...\")\n    !python main.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\n\nprint(\"\\nGPU 메모리 상태 (학습 후):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"✅ CNN5d 학습 완료\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn20d"
   },
   "outputs": [],
   "source": "# CNN20d 모델 학습 선택\n\nprint(\"🧠 CNN20d 학습 방식 선택:\")\nprint(\"   단일 모델: 빠름 (1개 모델)\")\nprint(\"   앙상블: 논문 방식 (5개 모델 평균)\")\n\n# 🔧 학습 방식 설정 (변경 가능)\nuse_ensemble = False  # True로 변경하면 앙상블 학습\n\nprint(\"GPU 메모리 상태 (학습 전):\")\ncheck_gpu_memory()\n\nif use_ensemble:\n    print(\"\\n🔥 CNN20d 앙상블 학습 (5개 모델)...\")\n    print(\"⚠️ 시간이 5배 더 걸립니다!\")\n    !python ensemble_train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble_runs 5 --use_original_format\nelse:\n    print(\"\\n🧠 CNN20d 단일 모델 학습...\")\n    !python main.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\n\nprint(\"\\nGPU 메모리 상태 (학습 후):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"✅ CNN20d 학습 완료\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_cnn60d"
   },
   "outputs": [],
   "source": "# CNN60d 모델 학습 선택 (메모리 집약적)\n\nprint(\"🧠 CNN60d 학습 방식 선택 (⚠️ 메모리 집약적):\")\nprint(\"   단일 모델: 빠름 (1개 모델)\")\nprint(\"   앙상블: 논문 방식 (5개 모델 평균)\")\n\n# 🔧 학습 방식 설정 (변경 가능)\nuse_ensemble = False  # True로 변경하면 앙상블 학습\n\nprint(\"GPU 메모리 상태 (학습 전):\")\nallocated, total = check_gpu_memory()\n\n# 메모리 부족 경고\nif allocated > total * 0.7:  # 70% 이상 사용 중이면 경고\n    print(\"⚠️ GPU 메모리 부족 위험! 추가 정리 수행...\")\n    cleanup_memory()\n\nif use_ensemble:\n    print(\"\\n🔥 CNN60d 앙상블 학습 (5개 모델)...\")\n    print(\"⚠️ 시간이 5배 더 걸립니다!\")\n    !python ensemble_train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble_runs 5 --use_original_format --batch_size 64\nelse:\n    print(\"\\n🧠 CNN60d 단일 모델 학습...\")\n    !python main.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --batch_size 64\n\nprint(\"\\nGPU 메모리 상태 (학습 후):\")\ncheck_gpu_memory()\ncleanup_memory()\nprint(\"✅ CNN60d 학습 완료\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_header"
   },
   "source": "# 모든 모델 평가 (원본 형식)\nprint(\"📈 포트폴리오 성과 평가 시작 (원본 .dat + .feather 형식)...\\n\")\n\nprint(\"1️⃣ CNN5d (Weekly Strategy)\")\n!python test.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\ncleanup_memory()\n\nprint(\"\\n2️⃣ CNN20d (Monthly Strategy)\")\n!python test.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\ncleanup_memory()\n\nprint(\"\\n3️⃣ CNN60d (Quarterly Strategy)\")\n!python test.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format\ncleanup_memory()\n\nprint(\"\\n📊 모든 평가 완료!\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_models"
   },
   "outputs": [],
   "source": "# 📈 포트폴리오 성과 평가 (앙상블 지원)\n\nprint(\"📈 포트폴리오 성과 평가 시작...\\n\")\nprint(\"🔧 평가 방식:\")\nprint(\"   단일 모델: 일반 예측\")\nprint(\"   앙상블: 5모델 평균 예측 (더 안정적)\")\n\n# 🔧 평가 방식 설정 (학습 방식과 일치시키세요)\nuse_ensemble_eval = False  # 앙상블로 학습했다면 True로 변경\n\nprint(\"1️⃣ CNN5d (Weekly Strategy)\")\nif use_ensemble_eval:\n    !python ensemble_test.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\nelse:\n    !python test.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format\ncleanup_memory()\n\nprint(\"\\n2️⃣ CNN20d (Monthly Strategy)\")\nif use_ensemble_eval:\n    !python ensemble_test.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\nelse:\n    !python test.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format\ncleanup_memory()\n\nprint(\"\\n3️⃣ CNN60d (Quarterly Strategy)\")\nif use_ensemble_eval:\n    !python ensemble_test.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format\nelse:\n    !python test.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format\ncleanup_memory()\n\nprint(\"\\n📊 모든 평가 완료!\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_header"
   },
   "source": [
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_training"
   },
   "outputs": [],
   "source": "# 최종 결과 요약 & GPU 메모리 분석\nprint(\"🎯 Re-Imaging Price Trends - 실행 완료!\")\nprint(\"=\" * 50)\n\n# GPU 메모리 분석 결과\nprint(\"\\n🖥️ GPU 메모리 요구사항 (배치크기 128):\")\nprint(\"   • CNN5d:  ~0.02GB (가장 가볍다)\")\nprint(\"   • CNN20d: ~0.09GB (중간)\")  \nprint(\"   • CNN60d: ~0.34GB (가장 무겁다)\")\nprint(\"\\n💡 실제 사용량은 데이터 로딩 + optimizer state로 2-3배 더 클 수 있음\")\n\nprint(\"\\n📱 Colab GPU 호환성:\")\nprint(\"   • T4 (16GB): 모든 모델 학습 가능\")\nprint(\"   • V100/A100: 대용량 배치 처리 가능\")\nprint(\"   • CNN60d는 배치크기 64 권장\")\n\n# 파일 크기 요약\nif os.path.exists('models'):\n    print(\"\\n🧠 학습된 모델:\")\n    for file in sorted(os.listdir('models')):\n        if file.endswith('.tar'):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"   ✅ {file} ({size_mb:.1f}MB)\")\n\n# 논문 성과와 비교\nprint(\"\\n📚 논문 예상 성과 (비교 참조):\")\nprint(\"   • Weekly (I5R5): H-L Sharpe = 7.15\")\nprint(\"   • Monthly (I20R20): H-L Sharpe = 2.16\") \nprint(\"   • Quarterly (I60R60): H-L Sharpe = 0.37\")\n\nprint(\"\\n🔧 사용된 형식:\")\nprint(\"   • 원본 형식 (.dat + .feather): 논문 저자와 동일\")\nprint(\"   • 메모리 효율적이고 Colab 친화적\")\n\nprint(\"\\n✅ 위의 포트폴리오 평가 결과와 비교해보세요!\")\nprint(\"\\n💾 최종 GPU 메모리 상태:\")\ncheck_gpu_memory()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": "# 최종 결과 요약 & 앙상블 정보\n\nprint(\"🎯 Re-Imaging Price Trends - 실행 완료!\")\nprint(\"=\" * 60)\n\n# GPU 메모리 분석 결과\nprint(\"\\n🖥️ GPU 메모리 요구사항 (배치크기 128):\")\nprint(\"   • CNN5d:  ~0.02GB (가장 가볍다)\")\nprint(\"   • CNN20d: ~0.09GB (중간)\")  \nprint(\"   • CNN60d: ~0.34GB (가장 무겁다)\")\nprint(\"\\n💡 실제 사용량은 데이터 로딩 + optimizer state로 2-3배 더 클 수 있음\")\n\nprint(\"\\n📱 Colab GPU 호환성:\")\nprint(\"   • T4 (16GB): 모든 모델 학습 가능\")\nprint(\"   • V100/A100: 대용량 배치 처리 가능\")\nprint(\"   • CNN60d는 배치크기 64 권장\")\n\n# 앙상블 vs 단일 모델 설명\nprint(\"\\n🧠 모델 학습 방식:\")\nprint(\"   • 단일 모델: 빠름, 테스트용\")\nprint(\"   • 앙상블 (5모델): 논문 방식, 더 안정적 성능\")\nprint(\"     - 동일 모델을 5번 독립 훈련\")\nprint(\"     - 예측 시 5개 결과 평균화\")\nprint(\"     - 확률적 변동성 감소\")\n\n# 파일 크기 요약\nif os.path.exists('models'):\n    print(\"\\n🧠 학습된 모델:\")\n    model_files = [f for f in os.listdir('models') if f.endswith('.tar')]\n    \n    # 단일 모델\n    single_models = [f for f in model_files if '_run' not in f]\n    if single_models:\n        print(\"   📁 단일 모델:\")\n        for file in sorted(single_models):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"     ✅ {file} ({size_mb:.1f}MB)\")\n    \n    # 앙상블 모델\n    ensemble_models = [f for f in model_files if '_run' in f]\n    if ensemble_models:\n        print(\"   📁 앙상블 모델:\")\n        for file in sorted(ensemble_models):\n            size_mb = os.path.getsize(f'models/{file}') / (1024**2)\n            print(f\"     ✅ {file} ({size_mb:.1f}MB)\")\n\n# 논문 성과와 비교\nprint(\"\\n📚 논문 예상 성과 (비교 참조):\")\nprint(\"   • Weekly (I5R5): H-L Sharpe = 7.15\")\nprint(\"   • Monthly (I20R20): H-L Sharpe = 2.16\") \nprint(\"   • Quarterly (I60R60): H-L Sharpe = 0.37\")\n\nprint(\"\\n🔧 사용된 형식:\")\nprint(\"   • 원본 형식 (.dat + .feather): 논문 저자와 동일\")\nprint(\"   • 메모리 효율적이고 Colab 친화적\")\n\nprint(\"\\n✅ 포트폴리오 평가 결과를 확인하여 논문과 비교해보세요!\")\nprint(\"\\n💾 최종 GPU 메모리 상태:\")\ncheck_gpu_memory()"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}