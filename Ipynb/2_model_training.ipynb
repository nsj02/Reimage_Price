{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Re-Imaging Price Trends - Comparative Model Training\n",
        "\n",
        "**Purpose**: Train models on both original and filled data for performance comparison\n",
        "\n",
        "**Prerequisites**: `1_image_generation.ipynb` completed for both data versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Environment setup\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# GPU check\n",
        "import torch\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "# GPU memory monitoring\n",
        "def check_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.cuda.current_device()\n",
        "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
        "        allocated = torch.cuda.memory_allocated(device)\n",
        "        print(f\"GPU memory: {allocated/1024**3:.1f}/{total_memory/1024**3:.1f}GB ({allocated/total_memory*100:.1f}%)\")\n",
        "        return allocated, total_memory\n",
        "    else:\n",
        "        print(\"GPU unavailable\")\n",
        "        return 0, 0\n",
        "\n",
        "def cleanup_memory():\n",
        "    import gc\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "    print(\"Memory cleaned\")\n",
        "\n",
        "check_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# COMPARATIVE TRAINING CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# Training method\n",
        "USE_ENSEMBLE = True    # True: ensemble (paper method), False: single model\n",
        "ENSEMBLE_RUNS = 5      # Number of ensemble models\n",
        "\n",
        "print(f\"=== COMPARATIVE TRAINING SETUP ===\")\n",
        "print(f\"Training method: {'Ensemble (' + str(ENSEMBLE_RUNS) + ' models)' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Data versions: Both original AND filled\")\n",
        "print(f\"Purpose: Performance comparison between datasets\")\n",
        "print(f\"\")\n",
        "print(f\"Output models:\")\n",
        "print(f\"  - CNN5d (original data): CNN5d_I5R5.tar\")\n",
        "print(f\"  - CNN5d (filled data):   CNN5d_I5R5_filled.tar\")\n",
        "print(f\"  - Same pattern for CNN20d and CNN60d\")\n",
        "print(f\"\")\n",
        "print(f\"This allows direct performance comparison!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_data"
      },
      "outputs": [],
      "source": [
        "# Check both original and filled data availability\n",
        "import os\n",
        "\n",
        "def check_data_version(version):\n",
        "    data_dir = 'img_data_reconstructed' if version == 'original' else 'img_data_reconstructed_filled'\n",
        "    \n",
        "    required_dirs = ['weekly_5d', 'monthly_20d', 'quarterly_60d']\n",
        "    all_ready = True\n",
        "    \n",
        "    print(f\"\\n{version.upper()} DATA:\")\n",
        "    for dir_name in required_dirs:\n",
        "        dir_path = os.path.join(data_dir, dir_name)\n",
        "        if os.path.exists(dir_path):\n",
        "            dat_files = len([f for f in os.listdir(dir_path) if f.endswith('.dat')])\n",
        "            feather_files = len([f for f in os.listdir(dir_path) if f.endswith('.feather')])\n",
        "            print(f\"  ‚úì {dir_name}: {dat_files} .dat, {feather_files} .feather files\")\n",
        "        else:\n",
        "            print(f\"  ‚úó {dir_name}: MISSING\")\n",
        "            all_ready = False\n",
        "    \n",
        "    return all_ready\n",
        "\n",
        "# Check both versions\n",
        "original_ready = check_data_version('original')\n",
        "filled_ready = check_data_version('filled')\n",
        "\n",
        "print(f\"\\n=== DATA AVAILABILITY SUMMARY ===\")\n",
        "print(f\"Original data: {'‚úÖ Ready' if original_ready else '‚ùå Missing'}\")\n",
        "print(f\"Filled data:   {'‚úÖ Ready' if filled_ready else '‚ùå Missing'}\")\n",
        "\n",
        "if original_ready and filled_ready:\n",
        "    print(f\"\\nüéâ Both datasets ready for comparative training!\")\n",
        "elif original_ready:\n",
        "    print(f\"\\n‚ö†Ô∏è  Only original data available. Run filled data generation first.\")\n",
        "elif filled_ready:\n",
        "    print(f\"\\n‚ö†Ô∏è  Only filled data available. Run original data generation first.\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå No data available. Run 1_image_generation.ipynb for both versions.\")\n",
        "\n",
        "# Set training flags\n",
        "CAN_TRAIN_ORIGINAL = original_ready\n",
        "CAN_TRAIN_FILLED = filled_ready"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_header"
      },
      "source": [
        "# CNN5d Training (Original vs Filled Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn5d_original"
      },
      "outputs": [],
      "source": [
        "# CNN5d Training - Original Data\n",
        "print(f\"=== CNN5d Training - ORIGINAL Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN5d_I5R5{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original data...\")\n",
        "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on original data...\")\n",
        "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format --data_version original\n",
        "    \n",
        "    print(\"‚úÖ CNN5d (original) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Original data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn5d_filled"
      },
      "outputs": [],
      "source": [
        "# CNN5d Training - Filled Data\n",
        "print(f\"=== CNN5d Training - FILLED Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN5d_I5R5_filled{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on filled data...\")\n",
        "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version filled\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on filled data...\")\n",
        "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format --data_version filled\n",
        "    \n",
        "    print(\"‚úÖ CNN5d (filled) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Filled data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_cnn20d_header"
      },
      "source": [
        "# CNN20d Training (Original vs Filled Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn20d_original"
      },
      "outputs": [],
      "source": [
        "# CNN20d Training - Original Data\n",
        "print(f\"=== CNN20d Training - ORIGINAL Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN20d_I20R20{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original data...\")\n",
        "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on original data...\")\n",
        "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format --data_version original\n",
        "    \n",
        "    print(\"‚úÖ CNN20d (original) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Original data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn20d_filled"
      },
      "outputs": [],
      "source": [
        "# CNN20d Training - Filled Data\n",
        "print(f\"=== CNN20d Training - FILLED Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN20d_I20R20_filled{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on filled data...\")\n",
        "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version filled\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on filled data...\")\n",
        "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format --data_version filled\n",
        "    \n",
        "    print(\"‚úÖ CNN20d (filled) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Filled data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_cnn60d_header"
      },
      "source": [
        "# CNN60d Training (Original vs Filled Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn60d_original"
      },
      "outputs": [],
      "source": [
        "# CNN60d Training - Original Data\n",
        "print(f\"=== CNN60d Training - ORIGINAL Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN60d_I60R60{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "print(f\"Warning: Most memory intensive!\")\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original data...\")\n",
        "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original --batch_size 64\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on original data...\")\n",
        "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --data_version original --batch_size 64\n",
        "    \n",
        "    print(\"‚úÖ CNN60d (original) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Original data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_cnn60d_filled"
      },
      "outputs": [],
      "source": [
        "# CNN60d Training - Filled Data\n",
        "print(f\"=== CNN60d Training - FILLED Data ===\")\n",
        "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
        "print(f\"Output: CNN60d_I60R60_filled{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
        "print(f\"Warning: Most memory intensive!\")\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    check_gpu_memory()\n",
        "    \n",
        "    if USE_ENSEMBLE:\n",
        "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on filled data...\")\n",
        "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version filled --batch_size 64\n",
        "    else:\n",
        "        print(f\"\\nTraining single model on filled data...\")\n",
        "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --data_version filled --batch_size 64\n",
        "    \n",
        "    print(\"‚úÖ CNN60d (filled) training completed\")\n",
        "else:\n",
        "    print(\"‚ùå Filled data not available - skipping\")\n",
        "\n",
        "cleanup_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_header"
      },
      "source": [
        "# Comparative Portfolio Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_cnn5d_comparison"
      },
      "outputs": [],
      "source": [
        "# CNN5d Comparative Evaluation\n",
        "print(f\"=== CNN5d COMPARATIVE EVALUATION ===\")\n",
        "print(f\"Strategy: Weekly (I5/R5)\")\n",
        "print(f\"Paper benchmark: Sharpe = 7.15\")\n",
        "print(f\"\")\n",
        "\n",
        "ensemble_flag = \"--ensemble\" if USE_ENSEMBLE else \"\"\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    print(\"üìä CNN5d - Original Data:\")\n",
        "    !python test.py --model CNN5d --image_days 5 --pred_days 5 {ensemble_flag} --use_original_format --data_version original\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN5d original model not available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    print(\"üìä CNN5d - Filled Data:\")\n",
        "    !python test.py --model CNN5d --image_days 5 --pred_days 5 {ensemble_flag} --use_original_format --data_version filled\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN5d filled model not available\")\n",
        "\n",
        "print(\"\\n‚úÖ CNN5d comparative evaluation completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_cnn20d_comparison"
      },
      "outputs": [],
      "source": [
        "# CNN20d Comparative Evaluation\n",
        "print(f\"=== CNN20d COMPARATIVE EVALUATION ===\")\n",
        "print(f\"Strategy: Monthly (I20/R20)\")\n",
        "print(f\"Paper benchmark: Sharpe = 2.16\")\n",
        "print(f\"\")\n",
        "\n",
        "ensemble_flag = \"--ensemble\" if USE_ENSEMBLE else \"\"\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    print(\"üìä CNN20d - Original Data:\")\n",
        "    !python test.py --model CNN20d --image_days 20 --pred_days 20 {ensemble_flag} --use_original_format --data_version original\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN20d original model not available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    print(\"üìä CNN20d - Filled Data:\")\n",
        "    !python test.py --model CNN20d --image_days 20 --pred_days 20 {ensemble_flag} --use_original_format --data_version filled\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN20d filled model not available\")\n",
        "\n",
        "print(\"\\n‚úÖ CNN20d comparative evaluation completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_cnn60d_comparison"
      },
      "outputs": [],
      "source": [
        "# CNN60d Comparative Evaluation\n",
        "print(f\"=== CNN60d COMPARATIVE EVALUATION ===\")\n",
        "print(f\"Strategy: Quarterly (I60/R60)\")\n",
        "print(f\"Paper benchmark: Sharpe = 0.37\")\n",
        "print(f\"\")\n",
        "\n",
        "ensemble_flag = \"--ensemble\" if USE_ENSEMBLE else \"\"\n",
        "\n",
        "if CAN_TRAIN_ORIGINAL:\n",
        "    print(\"üìä CNN60d - Original Data:\")\n",
        "    !python test.py --model CNN60d --image_days 60 --pred_days 60 {ensemble_flag} --use_original_format --data_version original\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN60d original model not available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "if CAN_TRAIN_FILLED:\n",
        "    print(\"üìä CNN60d - Filled Data:\")\n",
        "    !python test.py --model CNN60d --image_days 60 --pred_days 60 {ensemble_flag} --use_original_format --data_version filled\n",
        "    cleanup_memory()\n",
        "else:\n",
        "    print(\"‚ùå CNN60d filled model not available\")\n",
        "\n",
        "print(\"\\n‚úÖ CNN60d comparative evaluation completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_header"
      },
      "source": [
        "# Comparative Results Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_comparison"
      },
      "outputs": [],
      "source": [
        "# Comparative Results Analysis\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPARATIVE RESULTS ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def load_result(model, data_version, ensemble=USE_ENSEMBLE):\n",
        "    \"\"\"Load performance result from JSON file\"\"\"\n",
        "    eval_type = \"ensemble\" if ensemble else \"single\"\n",
        "    version_suffix = \"_filled\" if data_version == 'filled' else \"\"\n",
        "    \n",
        "    result_file = f\"results/{model}_I{model[3:]}R{model[3:]}{version_suffix}_{eval_type}_performance.json\"\n",
        "    \n",
        "    try:\n",
        "        with open(result_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = []\n",
        "models = ['CNN5d', 'CNN20d', 'CNN60d']\n",
        "strategies = ['Weekly (I5/R5)', 'Monthly (I20/R20)', 'Quarterly (I60/R60)']\n",
        "paper_benchmarks = [7.15, 2.16, 0.37]\n",
        "\n",
        "for i, (model, strategy, paper_sharpe) in enumerate(zip(models, strategies, paper_benchmarks)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{model} - {strategy}\")\n",
        "    print(f\"Paper benchmark: {paper_sharpe}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Load results\n",
        "    original_result = load_result(model, 'original')\n",
        "    filled_result = load_result(model, 'filled')\n",
        "    \n",
        "    # Extract key metrics\n",
        "    if original_result:\n",
        "        orig_sharpe = original_result['ls_sharpe_ratio']\n",
        "        orig_return = original_result['ls_annual_return'] * 100\n",
        "        orig_turnover = original_result['monthly_turnover'] * 100\n",
        "        print(f\"\\nüìä ORIGINAL Data:\")\n",
        "        print(f\"   Long-Short Sharpe: {orig_sharpe:.2f}\")\n",
        "        print(f\"   Annual Return: {orig_return:.2f}%\")\n",
        "        print(f\"   Monthly Turnover: {orig_turnover:.1f}%\")\n",
        "    else:\n",
        "        orig_sharpe = orig_return = orig_turnover = None\n",
        "        print(f\"\\n‚ùå ORIGINAL Data: No results\")\n",
        "    \n",
        "    if filled_result:\n",
        "        fill_sharpe = filled_result['ls_sharpe_ratio']\n",
        "        fill_return = filled_result['ls_annual_return'] * 100\n",
        "        fill_turnover = filled_result['monthly_turnover'] * 100\n",
        "        print(f\"\\nüìä FILLED Data:\")\n",
        "        print(f\"   Long-Short Sharpe: {fill_sharpe:.2f}\")\n",
        "        print(f\"   Annual Return: {fill_return:.2f}%\")\n",
        "        print(f\"   Monthly Turnover: {fill_turnover:.1f}%\")\n",
        "    else:\n",
        "        fill_sharpe = fill_return = fill_turnover = None\n",
        "        print(f\"\\n‚ùå FILLED Data: No results\")\n",
        "    \n",
        "    # Performance comparison\n",
        "    if orig_sharpe is not None and fill_sharpe is not None:\n",
        "        sharpe_diff = fill_sharpe - orig_sharpe\n",
        "        return_diff = fill_return - orig_return\n",
        "        \n",
        "        print(f\"\\nüîç COMPARISON:\")\n",
        "        print(f\"   Sharpe improvement: {sharpe_diff:+.2f} ({sharpe_diff/orig_sharpe*100:+.1f}%)\")\n",
        "        print(f\"   Return improvement: {return_diff:+.2f}pp\")\n",
        "        \n",
        "        if fill_sharpe > orig_sharpe:\n",
        "            print(f\"   üéâ Filled data WINS by {sharpe_diff:.2f} Sharpe points!\")\n",
        "        elif orig_sharpe > fill_sharpe:\n",
        "            print(f\"   üèÜ Original data WINS by {-sharpe_diff:.2f} Sharpe points!\")\n",
        "        else:\n",
        "            print(f\"   ü§ù TIE - Similar performance\")\n",
        "    \n",
        "    # Store for summary table\n",
        "    comparison_data.append({\n",
        "        'Model': model,\n",
        "        'Strategy': strategy,\n",
        "        'Paper_Sharpe': paper_sharpe,\n",
        "        'Original_Sharpe': orig_sharpe,\n",
        "        'Filled_Sharpe': fill_sharpe,\n",
        "        'Original_Return': orig_return,\n",
        "        'Filled_Return': fill_return\n",
        "    })\n",
        "\n",
        "# Summary table\n",
        "print(f\"\\n\\n{'='*80}\")\n",
        "print(f\"SUMMARY TABLE\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(f\"{'Model':<8} {'Strategy':<15} {'Paper':<8} {'Original':<10} {'Filled':<10} {'Winner':<10}\")\n",
        "print(f\"{'-'*75}\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    model = row['Model']\n",
        "    strategy = row['Strategy'].split()[0]  # Weekly/Monthly/Quarterly\n",
        "    paper = f\"{row['Paper_Sharpe']:.2f}\"\n",
        "    orig = f\"{row['Original_Sharpe']:.2f}\" if row['Original_Sharpe'] is not None else \"N/A\"\n",
        "    filled = f\"{row['Filled_Sharpe']:.2f}\" if row['Filled_Sharpe'] is not None else \"N/A\"\n",
        "    \n",
        "    # Determine winner\n",
        "    if row['Original_Sharpe'] is not None and row['Filled_Sharpe'] is not None:\n",
        "        if row['Filled_Sharpe'] > row['Original_Sharpe']:\n",
        "            winner = \"Filled\"\n",
        "        elif row['Original_Sharpe'] > row['Filled_Sharpe']:\n",
        "            winner = \"Original\"\n",
        "        else:\n",
        "            winner = \"Tie\"\n",
        "    else:\n",
        "        winner = \"N/A\"\n",
        "    \n",
        "    print(f\"{model:<8} {strategy:<15} {paper:<8} {orig:<10} {filled:<10} {winner:<10}\")\n",
        "\n",
        "print(f\"\\nüí° KEY INSIGHTS:\")\n",
        "if len([x for x in comparison_data if x['Original_Sharpe'] is not None and x['Filled_Sharpe'] is not None]) > 0:\n",
        "    filled_wins = sum(1 for x in comparison_data if x['Original_Sharpe'] is not None and x['Filled_Sharpe'] is not None and x['Filled_Sharpe'] > x['Original_Sharpe'])\n",
        "    total_comparisons = len([x for x in comparison_data if x['Original_Sharpe'] is not None and x['Filled_Sharpe'] is not None])\n",
        "    \n",
        "    print(f\"   Filled data wins: {filled_wins}/{total_comparisons} models\")\n",
        "    print(f\"   Missing data impact: {'Positive' if filled_wins > total_comparisons/2 else 'Negative' if filled_wins < total_comparisons/2 else 'Neutral'}\")\n",
        "    \n",
        "    if filled_wins > total_comparisons/2:\n",
        "        print(f\"   üéØ Recommendation: Use FILLED data for better performance\")\n",
        "    elif filled_wins < total_comparisons/2:\n",
        "        print(f\"   üéØ Recommendation: Use ORIGINAL data for better performance\")\n",
        "    else:\n",
        "        print(f\"   üéØ Recommendation: Both datasets perform similarly\")\n",
        "else:\n",
        "    print(f\"   No comparative results available yet\")\n",
        "\n",
        "print(f\"\\nüìÅ Result files saved in: results/\")\n",
        "if os.path.exists('results'):\n",
        "    result_files = [f for f in os.listdir('results') if f.endswith('.json')]\n",
        "    for f in sorted(result_files):\n",
        "        print(f\"   üìä {f}\")\n"
      ]
    }
  ]
}