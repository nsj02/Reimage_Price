{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# 1ï¸âƒ£ Re-Imaging Price Trends - ì´ë¯¸ì§€ ìƒì„±\n",
    "\n",
    "**ëª©ì **: ì£¼ê°€ ë°ì´í„°ë¥¼ ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ë””ìŠ¤í¬ì— ì €ì¥\n",
    "\n",
    "**ì™„ë£Œ í›„**: `2_model_training.ipynb` ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": "# í™˜ê²½ ì„¤ì • ë° ìµœì í™” í™•ì¸\n!pip install -r requirements.txt\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nos.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\nprint(f\"ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\nprint(f\"ğŸ“„ íŒŒì¼ ëª©ë¡: {[f for f in os.listdir('.') if not f.startswith('.')]}\")\n\n# Numba JIT ì„±ëŠ¥ ìµœì í™” í™•ì¸\ntry:\n    import numba\n    print(f\"âœ… Numba JIT ì‚¬ìš© ê°€ëŠ¥: {numba.__version__}\")\n    print(\"   ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì†ë„ê°€ 50-100ë°° í–¥ìƒë©ë‹ˆë‹¤!\")\nexcept ImportError:\n    print(\"âŒ Numba ì„¤ì¹˜ ì‹¤íŒ¨ - requirements.txt í™•ì¸ í•„ìš”\")\n\n# ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\nimport psutil\nmemory = psutil.virtual_memory()\nprint(f\"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {memory.available // (1024**3):.1f}GB\")\nif memory.available < 2 * (1024**3):  # 2GB ë¯¸ë§Œ\n    print(\"âš ï¸  ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ --parallel 1 ì˜µì…˜ ì‚¬ìš© ê¶Œì¥\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_data"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° íŒŒì¼ í™•ì¸\n",
    "data_files = [\n",
    "    'data/data_1993_2000_train_val.parquet',\n",
    "    'data/data_2001_2019_test.parquet'\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š ë°ì´í„° íŒŒì¼ í™•ì¸:\")\n",
    "all_exist = True\n",
    "for file in data_files:\n",
    "    if os.path.exists(file):\n",
    "        size_mb = os.path.getsize(file) / (1024**2)\n",
    "        print(f\"âœ… {file} ({size_mb:.1f}MB)\")\n",
    "    else:\n",
    "        print(f\"âŒ {file} ì—†ìŒ\")\n",
    "        all_exist = False\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"\\nâš ï¸ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. data/datageneration.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_images"
   },
   "outputs": [],
   "source": "# ğŸš€ ë…¼ë¬¸ ì €ì ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ ìƒì„± (.dat + .feather)\nprint(\"ğŸš€ ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...\")\n\n# 5ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\nprint(\"\\n1ï¸âƒ£ 5ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\")\n!python create_original_format.py --image_days 5 --mode train --sample_rate 1.0\n!python create_original_format.py --image_days 5 --mode test --sample_rate 1.0\n\n# 20ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\nprint(\"\\n2ï¸âƒ£ 20ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\")\n!python create_original_format.py --image_days 20 --mode train --sample_rate 1.0\n!python create_original_format.py --image_days 20 --mode test --sample_rate 1.0\n\n# 60ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\nprint(\"\\n3ï¸âƒ£ 60ì¼ ì´ë¯¸ì§€ (ì›ë³¸ í˜•ì‹)\")\n!python create_original_format.py --image_days 60 --mode train --sample_rate 1.0\n!python create_original_format.py --image_days 60 --mode test --sample_rate 1.0\n\nprint(\"\\nâœ… ëª¨ë“  ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!\")\nprint(\"ğŸ“Š ì €ì¥ í˜•ì‹: .dat (ì´ë¯¸ì§€) + .feather (ë¼ë²¨)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_images"
   },
   "outputs": [],
   "source": "# ìƒì„±ëœ ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ í™•ì¸\nimport pandas as pd\nimport os\nimport numpy as np\n\nprint(\"ğŸ“Š ìƒì„±ëœ ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ ìš”ì•½:\")\n\n# ì›ë³¸ í˜•ì‹ ë””ë ‰í† ë¦¬ í™•ì¸\noriginal_dirs = {\n    'weekly_5d': (5, '5d_week_has_vb_[5]_ma'),\n    'monthly_20d': (20, '20d_month_has_vb_[20]_ma'), \n    'quarterly_60d': (60, '60d_quarter_has_vb_[60]_ma')\n}\n\nbase_dir = 'img_data_reconstructed'\nif os.path.exists(base_dir):\n    total_images = 0\n    total_size_gb = 0\n    success_count = 0\n    \n    for dir_name, (win_size, prefix) in original_dirs.items():\n        img_dir = os.path.join(base_dir, dir_name)\n        \n        if os.path.exists(img_dir):\n            # .dat ë° .feather íŒŒì¼ í™•ì¸\n            dat_files = [f for f in os.listdir(img_dir) if f.endswith('.dat')]\n            feather_files = [f for f in os.listdir(img_dir) if f.endswith('.feather')]\n            \n            dir_images = 0\n            dir_size = 0\n            \n            # ê° ì—°ë„ë³„ íŒŒì¼ í™•ì¸\n            for dat_file in dat_files:\n                dat_path = os.path.join(img_dir, dat_file)\n                \n                # ì´ë¯¸ì§€ ê°œìˆ˜ ê³„ì‚° (.dat íŒŒì¼ í¬ê¸° ê¸°ë°˜)\n                file_size = os.path.getsize(dat_path)\n                if win_size == 5:\n                    image_size = 32 * 15  # 5ì¼: 32x15\n                elif win_size == 20:\n                    image_size = 64 * 60  # 20ì¼: 64x60  \n                else:  # 60\n                    image_size = 96 * 180  # 60ì¼: 96x180\n                \n                num_images = file_size // image_size\n                dir_images += num_images\n                dir_size += file_size\n            \n            # .feather íŒŒì¼ í¬ê¸° ì¶”ê°€\n            for feather_file in feather_files:\n                feather_path = os.path.join(img_dir, feather_file)\n                dir_size += os.path.getsize(feather_path)\n            \n            size_gb = dir_size / (1024**3)\n            total_size_gb += size_gb\n            \n            print(f\"âœ… {dir_name}: {dir_images:,}ê°œ ì´ë¯¸ì§€, {size_gb:.2f}GB\")\n            print(f\"   .dat íŒŒì¼: {len(dat_files)}ê°œ, .feather íŒŒì¼: {len(feather_files)}ê°œ\")\n            \n            total_images += dir_images\n            success_count += 1\n        else:\n            print(f\"âŒ {dir_name}: ìƒì„±ë˜ì§€ ì•ŠìŒ\")\n    \n    print(f\"\\nğŸ“ˆ ìµœì¢… ê²°ê³¼:\")\n    print(f\"   ì„±ê³µ: {success_count}/{len(original_dirs)} ë””ë ‰í† ë¦¬\")\n    print(f\"   ì´ ì´ë¯¸ì§€: {total_images:,}ê°œ\")\n    print(f\"   ì´ ìš©ëŸ‰: {total_size_gb:.2f}GB\")\n    print(f\"   ì´ë¯¸ì§€ë‹¹ í‰ê·  ìš©ëŸ‰: {total_size_gb*1024*1024/max(total_images,1):.1f}KB\")\n    \n    if success_count == len(original_dirs):\n        print(f\"\\nğŸ‰ ëª¨ë“  ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!\")\n        print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {base_dir}/\")\n        print(f\"ğŸ“Š í˜•ì‹: .dat (ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€) + .feather (ë¼ë²¨)\")\n        print(f\"\\nâ¡ï¸  ë…¼ë¬¸ ì €ì ì›ë³¸ê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨\")\n    else:\n        print(f\"\\nâš ï¸  {len(original_dirs)-success_count}ê°œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨\")\n        print(\"   create_original_format.py ì˜¤ë¥˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n        \n    # label_columns.txt íŒŒì¼ í™•ì¸\n    label_file = os.path.join(base_dir, 'label_columns.txt')\n    if os.path.exists(label_file):\n        print(f\"\\nğŸ“‹ ë©”íƒ€ë°ì´í„°: {label_file} ìƒì„±ë¨\")\n        with open(label_file, 'r') as f:\n            print(\"   ë‚´ìš©:\")\n            for line in f.readlines()[:3]:  # ì²˜ìŒ 3ì¤„ë§Œ í‘œì‹œ\n                print(f\"   {line.strip()}\")\nelse:\n    print(f\"âŒ {base_dir} ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n    print(\"   create_original_format.py ì‹¤í–‰ì„ í™•ì¸í•˜ì„¸ìš”.\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}