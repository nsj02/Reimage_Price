#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ensemble_test.py - ë…¼ë¬¸ ë°©ì‹ 5ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡

ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰í•œ ëŒ€ë¡œ 5ê°œì˜ ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· í•˜ì—¬
ìµœì¢… ì˜ˆì¸¡ì¹˜ë¡œ ì‚¬ìš©í•˜ëŠ” ì•™ìƒë¸” ë°±í…ŒìŠ¤íŒ…

ì‚¬ìš©ë²•:
    python ensemble_test.py --model CNN5d --image_days 5 --pred_days 5
"""

from __init__ import *
import model as _M
import dataset as _D
import dataset_original as _D_ORIG
import argparse
import numpy as np
from tqdm import tqdm

device = 'cuda' if torch.cuda.is_available() else 'cpu'

def load_ensemble_models(model_class, model_base_name, num_models=5):
    """
    ì•™ìƒë¸” ëª¨ë¸ë“¤ì„ ë¡œë“œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    models = []
    loaded_count = 0
    
    for run_idx in range(1, num_models + 1):
        model_file = f"models/{model_base_name}_run{run_idx}.tar"
        
        if os.path.exists(model_file):
            try:
                model = model_class()
                state_dict = torch.load(model_file, map_location=device)
                model.load_state_dict(state_dict['model_state_dict'])
                model.eval()
                model.to(device)
                models.append(model)
                loaded_count += 1
                print(f"âœ… ëª¨ë¸ {run_idx} ë¡œë“œ: {model_file}")
            except Exception as e:
                print(f"âŒ ëª¨ë¸ {run_idx} ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_file}")
    
    print(f"ì´ {loaded_count}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return models

def ensemble_predict(models, test_loader):
    """
    ì•™ìƒë¸” ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ ë° í‰ê· í™”
    """
    predictions = []
    num_models = len(models)
    
    if num_models == 0:
        raise ValueError("ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    print(f"ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ ({num_models}ê°œ ëª¨ë¸)...")
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(tqdm(test_loader, desc="Ensemble Predicting")):
            images, label_5, label_20, label_60, ret5, ret20, ret60 = batch_data
            
            # GPUë¡œ ì´ë¯¸ì§€ ì „ì†¡ (ëª¨ë¸ì—ì„œ unsqueeze ì²˜ë¦¬)
            images = images.float().to(device)  # [batch, H, W]
            
            # ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìˆ˜ì§‘ (BCE ë°©ì‹)
            batch_predictions = []
            for model in models:
                output = model(images)  # ì´ë¯¸ Sigmoid ì ìš©ë¨
                up_probs = output.squeeze().cpu().numpy()  # ìƒìŠ¹ í™•ë¥ 
                batch_predictions.append(up_probs)
            
            # ì•™ìƒë¸” í‰ê·  (ë…¼ë¬¸ ë°©ì‹)
            ensemble_up_probs = np.mean(batch_predictions, axis=0)
            
            # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
            batch_start_idx = batch_idx * test_loader.batch_size
            for i in range(len(ensemble_up_probs)):
                predictions.append({
                    'image_id': batch_start_idx + i,
                    'up_prob': ensemble_up_probs[i],
                    'actual_label_5': label_5[i].item(),
                    'actual_label_20': label_20[i].item(),
                    'actual_label_60': label_60[i].item(),
                    'actual_ret5': ret5[i].item(),
                    'actual_ret20': ret20[i].item(),
                    'actual_ret60': ret60[i].item()
                })
    
    return predictions

def decile_portfolio_backtest_ensemble(model_class, label_type, model_base_name, image_days, pred_days, use_original_format=False, num_models=5):
    """
    ì•™ìƒë¸” ëª¨ë¸ì„ ì‚¬ìš©í•œ decile í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ…
    """
    
    print(f"ğŸ”¥ ì•™ìƒë¸” ë°±í…ŒìŠ¤íŒ… ì‹œì‘")
    print(f"   ëª¨ë¸: {model_base_name}")
    print(f"   ì•™ìƒë¸” ëª¨ë¸ ìˆ˜: {num_models}ê°œ")
    print(f"   ë¼ë²¨ íƒ€ì…: {label_type}")
    
    # ì•™ìƒë¸” ëª¨ë¸ë“¤ ë¡œë“œ
    models = load_ensemble_models(model_class, model_base_name, num_models)
    
    if len(models) == 0:
        print("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ensemble_train.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
    if use_original_format:
        print(f"ì›ë³¸ í˜•ì‹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
        test_dataset = _D_ORIG.load_original_dataset(
            win_size=image_days,
            mode='test',
            label_type=label_type
        )
        if test_dataset is None:
            print(f"ì›ë³¸ í˜•ì‹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    else:
        # ìµœì í™”ëœ í˜•ì‹
        image_dir = f"images/test_I{image_days}R{pred_days}"
        if not os.path.exists(os.path.join(image_dir, 'metadata.csv')):
            print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
            return None
        test_dataset = _D.PrecomputedImageDataset(image_dir, label_type)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=256, shuffle=False  # ë°°ì¹˜ í¬ê¸° í¬ê²Œ (ì˜ˆì¸¡ë§Œ)
    )
    
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset):,}ê°œ")
    
    # ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = ensemble_predict(models, test_loader)
    
    print(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions):,}ê°œ")
    
    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰
    df_predictions = []
    for pred in predictions:
        # ë¼ë²¨ íƒ€ì…ì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” ì‹¤ì œ ë¼ë²¨ê³¼ ìˆ˜ìµë¥  ì„ íƒ
        if label_type == 'RET5':
            actual_label = pred['actual_label_5']
            actual_return = pred['actual_ret5']
        elif label_type == 'RET20':
            actual_label = pred['actual_label_20']
            actual_return = pred['actual_ret20']
        else:  # RET60
            actual_label = pred['actual_label_60']
            actual_return = pred['actual_ret60']
        
        # ë‚ ì§œ/ì¢…ëª© ì •ë³´ ì¶”ê°€ (ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        image_id = pred['image_id']
        if hasattr(test_dataset, 'labels_df') and image_id < len(test_dataset.labels_df):
            date = test_dataset.labels_df.iloc[image_id]['Date']
            stock_id = test_dataset.labels_df.iloc[image_id]['StockID']
        else:
            date = image_id  # ì„ì‹œë¡œ image_id ì‚¬ìš©
            stock_id = f'stock_{image_id}'
        
        df_predictions.append({
            'image_id': image_id,
            'date': date,
            'stock_id': stock_id,
            'up_prob': pred['up_prob'],
            'actual_label': actual_label,
            'actual_return': actual_return
        })
    
    df = pd.DataFrame(df_predictions)
    print(f"ì•™ìƒë¸” ì˜ˆì¸¡ DataFrame: {len(df):,}ê°œ")
    
    # test.pyì˜ calculate_decile_performance í•¨ìˆ˜ ì¬ì‚¬ìš©
    from test import calculate_decile_performance
    portfolio_performance = calculate_decile_performance(df, pred_days)
    
    return portfolio_performance

def main():
    parser = argparse.ArgumentParser(description='CNN ì•™ìƒë¸” ëª¨ë¸ í‰ê°€')
    parser.add_argument('--model', type=str, required=True, 
                       choices=['CNN5d', 'CNN20d', 'CNN60d'],
                       help='ëª¨ë¸ íƒ€ì…')
    parser.add_argument('--image_days', type=int, required=True,
                       choices=[5, 20, 60],
                       help='ì´ë¯¸ì§€ ìœˆë„ìš° í¬ê¸° (ì¼)')
    parser.add_argument('--pred_days', type=int, required=True,
                       choices=[5, 20, 60], 
                       help='ì˜ˆì¸¡ ê¸°ê°„ (ì¼)')
    parser.add_argument('--num_models', type=int, default=5,
                       help='ì•™ìƒë¸” ëª¨ë¸ ìˆ˜ (default: 5ê°œ)')
    parser.add_argument('--use_original_format', action='store_true',
                       help='ì›ë³¸ í˜•ì‹ (.dat + .feather) ì‚¬ìš©')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ í´ë˜ìŠ¤ ë§¤í•‘
    model_classes = {
        'CNN5d': _M.CNN5d,
        'CNN20d': _M.CNN20d, 
        'CNN60d': _M.CNN60d
    }
    
    model_class = model_classes[args.model]
    model_base_name = f"{args.model}_I{args.image_days}R{args.pred_days}"
    label_type = f'RET{args.pred_days}'
    
    # ì•™ìƒë¸” ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰
    results = decile_portfolio_backtest_ensemble(
        model_class=model_class,
        label_type=label_type,
        model_base_name=model_base_name,
        image_days=args.image_days,
        pred_days=args.pred_days,
        use_original_format=args.use_original_format,
        num_models=args.num_models
    )
    
    if results:
        print(f"\n{'='*60}")
        print(f"ğŸ‰ ì•™ìƒë¸” Decile í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ({model_base_name})")
        print(f"{'='*60}")
        print(f"Long-Short Sharpe Ratio:  {results['ls_sharpe_ratio']:.2f}")
        print(f"Long-Short ì—°ê°„ ìˆ˜ìµë¥ :   {results['ls_annual_return']:.4f} ({results['ls_annual_return']*100:.2f}%)")
        print(f"Long-Short ì—°ê°„ ë³€ë™ì„±:   {results['ls_annual_vol']:.4f} ({results['ls_annual_vol']*100:.2f}%)")
        print(f"")
        print(f"Long (Decile 1) ì„±ê³¼:")
        print(f"  ì—°ê°„ ìˆ˜ìµë¥ :            {results['long_annual_return']:.4f} ({results['long_annual_return']*100:.2f}%)")
        print(f"  Sharpe Ratio:          {results['long_sharpe_ratio']:.2f}")
        print(f"")
        print(f"Short (Decile 10) ì„±ê³¼:")
        print(f"  ì—°ê°„ ìˆ˜ìµë¥ :            {results['short_annual_return']:.4f} ({results['short_annual_return']*100:.2f}%)")
        print(f"  Sharpe Ratio:          {results['short_sharpe_ratio']:.2f}")
        print(f"")
        print(f"ì›”ê°„ Turnover:           {results['monthly_turnover']:.1f}%")
        print(f"ì´ ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„:        {results['total_periods']:,}ê°œ")
        print(f"ì•™ìƒë¸” ëª¨ë¸ ìˆ˜:          {args.num_models}ê°œ")
        print(f"{'='*60}")
        
        # Decileë³„ ìƒì„¸ ì„±ê³¼
        print(f"\nDecileë³„ ì„±ê³¼:")
        print(f"{'Decile':<8}{'ì—°ê°„ìˆ˜ìµë¥ ':<12}{'Sharpe':<8}")
        print(f"{'-'*28}")
        for decile_stat in results['decile_performance']:
            print(f"{decile_stat['decile']:<8}{decile_stat['annual_return']*100:>8.2f}%{decile_stat['sharpe_ratio']:>8.2f}")
        
        # ê²°ê³¼ ì €ì¥
        os.makedirs('results', exist_ok=True)
        result_file = f"results/{model_base_name}_ensemble_performance.json"
        
        import json
        with open(result_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nê²°ê³¼ ì €ì¥: {result_file}")
    else:
        print("âŒ ì•™ìƒë¸” ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨")

if __name__ == '__main__':
    main()