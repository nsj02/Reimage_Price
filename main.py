#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Re-Imaging Price Trends - Main Training Script
ë…¼ë¬¸ êµ¬í˜„: ê³ ì • ê¸°ê°„ í•™ìŠµ (1993-2000 train, 2001-2019 test)

ì‚¬ìš©ë²•:
    python main.py --model CNN5d --image_days 5 --pred_days 5
    python main.py --model CNN20d --image_days 20 --pred_days 20
    python main.py --model CNN60d --image_days 60 --pred_days 60
"""

from __init__ import *
import model as _M
import train as _T
import dataset as _D
import dataset_original as _D_ORIG
import argparse
import os

def main():
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='CNN ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ')
    parser.add_argument('--model', type=str, required=True, 
                       choices=['CNN5d', 'CNN20d', 'CNN60d'],
                       help='ëª¨ë¸ íƒ€ì…')
    parser.add_argument('--image_days', type=int, required=True,
                       choices=[5, 20, 60],
                       help='ì´ë¯¸ì§€ ìœˆë„ìš° í¬ê¸° (ì¼)')
    parser.add_argument('--pred_days', type=int, required=True,
                       choices=[5, 20, 60], 
                       help='ì˜ˆì¸¡ ê¸°ê°„ (ì¼)')
    parser.add_argument('--sample_rate', type=float, default=1.0,
                       help='ë°ì´í„° ìƒ˜í”Œë§ ë¹„ìœ¨ (default: 1.0)')
    parser.add_argument('--batch_size', type=int, default=128,
                       help='ë°°ì¹˜ í¬ê¸° (default: 128)')
    parser.add_argument('--epochs', type=int, default=100,
                       help='ìµœëŒ€ ì—í¬í¬ (default: 100)')
    parser.add_argument('--lr', type=float, default=1e-5,
                       help='í•™ìŠµë¥  (default: 1e-5)')
    parser.add_argument('--use_original_format', action='store_true',
                       help='ì›ë³¸ í˜•ì‹ (.dat + .feather) ì‚¬ìš©')
    parser.add_argument('--ensemble_runs', type=int, default=1,
                       help='ì•™ìƒë¸” ì‹¤í–‰ íšŸìˆ˜ (ë…¼ë¬¸: 5íšŒ, default: 1íšŒ)')
    
    args = parser.parse_args()
    
    print(f"ëª¨ë¸ í•™ìŠµ ì‹œì‘: {args.model}")
    print(f"  ì´ë¯¸ì§€ ìœˆë„ìš°: {args.image_days}ì¼")
    print(f"  ì˜ˆì¸¡ ê¸°ê°„: {args.pred_days}ì¼") 
    print(f"  ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  í•™ìŠµë¥ : {args.lr}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"  ë””ë°”ì´ìŠ¤: {device}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('models', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    
    # ì•™ìƒë¸” í•™ìŠµ ë£¨í”„
    for run_idx in range(args.ensemble_runs):
        print(f"\n{'='*60}")
        print(f"ì•™ìƒë¸” ì‹¤í–‰ {run_idx+1}/{args.ensemble_runs}")
        print(f"{'='*60}")
        
        # íŒŒì¼ëª… ì„¤ì • (ì•™ìƒë¸”ìš©)
        if args.ensemble_runs > 1:
            model_name = f"{args.model}_I{args.image_days}R{args.pred_days}_run{run_idx+1}"
        else:
            model_name = f"{args.model}_I{args.image_days}R{args.pred_days}"
        
        model_file = f"models/{model_name}.tar"
        log_file = f"logs/{model_name}.csv"
        
        # ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ í™•ì¸
        if os.path.exists(model_file):
            print(f"ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ ì¡´ì¬: {model_file}")
            print("ë‹¤ìŒ ì•™ìƒë¸” ì‹¤í–‰ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        # ë°ì´í„°ì…‹ ë¡œë“œ (ì•™ìƒë¸” ì‹¤í–‰ë§ˆë‹¤ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ëœë¤ì„± í™•ë³´)
        if args.use_original_format:
            print(f"\nì›ë³¸ í˜•ì‹ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
            full_dataset = _D_ORIG.load_original_dataset(
                win_size=args.image_days,
                mode='train',
                label_type=f'RET{args.pred_days}'
            )
            if full_dataset is None:
                print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì›ë³¸ í˜•ì‹ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”:")
                print(f"python create_original_format.py --image_days {args.image_days} --mode train")
                return
        else:
            # ì‚¬ì „ ìƒì„±ëœ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸
            image_dir = f"images/train_I{args.image_days}R{args.pred_days}"
            metadata_file = os.path.join(image_dir, 'metadata.csv')
            
            if not os.path.exists(metadata_file):
                print(f"\nâŒ ì‚¬ì „ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
                print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”:")
                print(f"python create_images_optimized.py --image_days {args.image_days} --mode train --pred_days {args.pred_days}")
                return
            
            # ì‚¬ì „ ìƒì„±ëœ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ë¡œë“œ
            print(f"\nì‚¬ì „ ìƒì„±ëœ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘: {image_dir}")
            full_dataset = _D.PrecomputedImageDataset(
                image_dir=image_dir,
                label_type=f'RET{args.pred_days}'
            )
        
        # í›ˆë ¨/ê²€ì¦ ë¶„í•  (ë…¼ë¬¸: 70:30 ëœë¤ ë¶„í• ) - ì•™ìƒë¸”ë§ˆë‹¤ ë‹¤ë¥¸ ë¶„í• ë¡œ ëœë¤ì„± í™•ë³´
        train_size = int(len(full_dataset) * 0.7)
        valid_size = len(full_dataset) - train_size
        
        train_dataset, valid_dataset = torch.utils.data.random_split(
            full_dataset, [train_size, valid_size]
        )
        
        # DataLoader ìƒì„±
        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=args.batch_size, shuffle=True
        )
        valid_loader = torch.utils.data.DataLoader(
            valid_dataset, batch_size=args.batch_size, shuffle=True
        )
        
        print(f"í›ˆë ¨ ë°ì´í„°: {len(train_dataset):,}ê°œ")
        print(f"ê²€ì¦ ë°ì´í„°: {len(valid_dataset):,}ê°œ")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        print(f"\n{args.model} ëª¨ë¸ ì´ˆê¸°í™”...")
        if args.model == 'CNN5d':
            model = _M.CNN5d()
        elif args.model == 'CNN20d':
            model = _M.CNN20d() 
        elif args.model == 'CNN60d':
            model = _M.CNN60d()
        
        model.to(device)
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
        
        # ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € (Sigmoid + BCELoss)
        criterion = nn.BCELoss().to(device)
        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.01)
        
        # ëª¨ë¸ í•™ìŠµ
        print(f"\nëª¨ë¸ í•™ìŠµ ì‹œì‘ (ìµœëŒ€ {args.epochs}ì—í¬í¬)...")
        train_loss_set, valid_loss_set, train_acc_set, valid_acc_set = _T.train_n_epochs(
            n_epochs=args.epochs,
            model=model,
            label_type=f'RET{args.pred_days}',
            train_loader=train_loader,
            valid_loader=valid_loader,
            criterion=criterion,
            optimizer=optimizer,
            savefile=model_file,
            early_stop_epoch=2  # ë…¼ë¬¸: 2ì—í¬í¬
        )
        
        # ê²°ê³¼ ë¡œê·¸ ì €ì¥
        print(f"\ní•™ìŠµ ë¡œê·¸ ì €ì¥: {log_file}")
        log = pd.DataFrame({
            'train_loss': train_loss_set,
            'train_acc': train_acc_set,
            'valid_loss': valid_loss_set,
            'valid_acc': valid_acc_set
        })
        log.to_csv(log_file, index=False)
        
        print(f"\ní•™ìŠµ ì™„ë£Œ!")
        print(f"  ëª¨ë¸: {model_file}")
        print(f"  ë¡œê·¸: {log_file}")
        print(f"  ìµœì¢… ê²€ì¦ ì •í™•ë„: {valid_acc_set[-1]:.4f}")
    
    print(f"\nğŸ‰ ëª¨ë“  ì•™ìƒë¸” ì‹¤í–‰ ì™„ë£Œ!")

if __name__ == '__main__':
    main()