{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Imaging Price Trends - 2-Way Data Comparison\n",
    "\n",
    "**Purpose**: Train models on 2 different data versions for performance comparison:\n",
    "1. **original_author**: ÎÖºÎ¨∏ Ï†ÄÏûêÏùò ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ (img_data/)\n",
    "2. **reconstructed**: Ïö∞Î¶¨Í∞Ä Ïû¨Íµ¨ÏÑ±Ìïú Îç∞Ïù¥ÌÑ∞ (img_data_reconstructed/)\n",
    "\n",
    "**Prerequisites**: Both datasets generated and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/ReImaging_Price_Trends')\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# GPU check\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# GPU memory monitoring\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        allocated = torch.cuda.memory_allocated(device)\n",
    "        print(f\"GPU memory: {allocated/1024**3:.1f}/{total_memory/1024**3:.1f}GB ({allocated/total_memory*100:.1f}%)\")\n",
    "        return allocated, total_memory\n",
    "    else:\n",
    "        print(\"GPU unavailable\")\n",
    "        return 0, 0\n",
    "\n",
    "def cleanup_memory():\n",
    "    import gc\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    print(\"Memory cleaned\")\n",
    "\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-WAY COMPARATIVE TRAINING CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Training method\n",
    "USE_ENSEMBLE = True    # True: ensemble (paper method), False: single model\n",
    "ENSEMBLE_RUNS = 5      # Number of ensemble models\n",
    "\n",
    "print(f\"=== 2-WAY COMPARATIVE TRAINING SETUP ===\")\n",
    "print(f\"Training method: {'Ensemble (' + str(ENSEMBLE_RUNS) + ' models)' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Data versions: 2-way comparison\")\n",
    "print(f\"  1. original_author  (img_data/)\")\n",
    "print(f\"  2. reconstructed    (img_data_reconstructed/)\")\n",
    "print(f\"\")\n",
    "print(f\"Output models:\")\n",
    "print(f\"  - CNN20d_I20R20_original_author_run1-5.tar\")\n",
    "print(f\"  - CNN20d_I20R20_reconstructed_run1-5.tar\")\n",
    "print(f\"\")\n",
    "print(f\"üéØ Purpose: Compare original vs reconstructed data performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both data versions availability\n",
    "import os\n",
    "\n",
    "def check_data_version(version_name, data_dir):\n",
    "    required_dirs = ['weekly_5d', 'monthly_20d', 'quarterly_60d']\n",
    "    all_ready = True\n",
    "    \n",
    "    print(f\"\\n{version_name.upper()} DATA ({data_dir}):\")\n",
    "    for dir_name in required_dirs:\n",
    "        dir_path = os.path.join(data_dir, dir_name)\n",
    "        if os.path.exists(dir_path):\n",
    "            dat_files = len([f for f in os.listdir(dir_path) if f.endswith('.dat')])\n",
    "            feather_files = len([f for f in os.listdir(dir_path) if f.endswith('.feather')])\n",
    "            print(f\"  ‚úì {dir_name}: {dat_files} .dat, {feather_files} .feather files\")\n",
    "        else:\n",
    "            print(f\"  ‚úó {dir_name}: MISSING\")\n",
    "            all_ready = False\n",
    "    \n",
    "    return all_ready\n",
    "\n",
    "# Check both versions\n",
    "original_author_ready = check_data_version('ORIGINAL AUTHOR', 'img_data')\n",
    "reconstructed_ready = check_data_version('RECONSTRUCTED', 'img_data_reconstructed') \n",
    "\n",
    "print(f\"\\n=== DATA AVAILABILITY SUMMARY ===\")\n",
    "print(f\"Original Author: {'‚úÖ Ready' if original_author_ready else '‚ùå Missing'}\")\n",
    "print(f\"Reconstructed:   {'‚úÖ Ready' if reconstructed_ready else '‚ùå Missing'}\")\n",
    "\n",
    "ready_count = sum([original_author_ready, reconstructed_ready])\n",
    "if ready_count == 2:\n",
    "    print(f\"\\nüéâ Both datasets ready for comparative training!\")\n",
    "elif ready_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Only {ready_count}/2 datasets available. Generate missing datasets first.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No datasets available. Run data generation first.\")\n",
    "\n",
    "# Set training flags\n",
    "CAN_TRAIN_ORIGINAL_AUTHOR = original_author_ready\n",
    "CAN_TRAIN_RECONSTRUCTED = reconstructed_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN5d Training (Original vs Reconstructed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN5d Training - Original Author Data\n",
    "print(f\"=== CNN5d Training - ORIGINAL AUTHOR Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN5d_I5R5_original_author{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "\n",
    "if CAN_TRAIN_ORIGINAL_AUTHOR:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original author data...\")\n",
    "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original_author\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on original author data...\")\n",
    "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format --data_version original_author\n",
    "    \n",
    "    print(\"‚úÖ CNN5d (original author) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Original author data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN5d Training - Reconstructed Data\n",
    "print(f\"=== CNN5d Training - RECONSTRUCTED Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN5d_I5R5_reconstructed{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "\n",
    "if CAN_TRAIN_RECONSTRUCTED:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on reconstructed data...\")\n",
    "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version reconstructed\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on reconstructed data...\")\n",
    "        !python train.py --model CNN5d --image_days 5 --pred_days 5 --use_original_format --data_version reconstructed\n",
    "    \n",
    "    print(\"‚úÖ CNN5d (reconstructed) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Reconstructed data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN20d Training (Original vs Reconstructed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN20d Training - Original Author Data\n",
    "print(f\"=== CNN20d Training - ORIGINAL AUTHOR Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN20d_I20R20_original_author{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "\n",
    "if CAN_TRAIN_ORIGINAL_AUTHOR:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original author data...\")\n",
    "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original_author\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on original author data...\")\n",
    "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format --data_version original_author\n",
    "    \n",
    "    print(\"‚úÖ CNN20d (original author) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Original author data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN20d Training - Reconstructed Data\n",
    "print(f\"=== CNN20d Training - RECONSTRUCTED Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN20d_I20R20_reconstructed{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "\n",
    "if CAN_TRAIN_RECONSTRUCTED:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on reconstructed data...\")\n",
    "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version reconstructed\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on reconstructed data...\")\n",
    "        !python train.py --model CNN20d --image_days 20 --pred_days 20 --use_original_format --data_version reconstructed\n",
    "    \n",
    "    print(\"‚úÖ CNN20d (reconstructed) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Reconstructed data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN60d Training (Original vs Reconstructed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN60d Training - Original Author Data\n",
    "print(f\"=== CNN60d Training - ORIGINAL AUTHOR Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN60d_I60R60_original_author{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "print(f\"Warning: Most memory intensive!\")\n",
    "\n",
    "if CAN_TRAIN_ORIGINAL_AUTHOR:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on original author data...\")\n",
    "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version original_author --batch_size 64\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on original author data...\")\n",
    "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --data_version original_author --batch_size 64\n",
    "    \n",
    "    print(\"‚úÖ CNN60d (original author) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Original author data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN60d Training - Reconstructed Data\n",
    "print(f\"=== CNN60d Training - RECONSTRUCTED Data ===\")\n",
    "print(f\"Method: {'Ensemble' if USE_ENSEMBLE else 'Single model'}\")\n",
    "print(f\"Output: CNN60d_I60R60_reconstructed{'_run1-5' if USE_ENSEMBLE else ''}.tar\")\n",
    "print(f\"Warning: Most memory intensive!\")\n",
    "\n",
    "if CAN_TRAIN_RECONSTRUCTED:\n",
    "    check_gpu_memory()\n",
    "    \n",
    "    if USE_ENSEMBLE:\n",
    "        print(f\"\\nTraining ensemble ({ENSEMBLE_RUNS} models) on reconstructed data...\")\n",
    "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --ensemble --ensemble_runs {ENSEMBLE_RUNS} --use_original_format --data_version reconstructed --batch_size 64\n",
    "    else:\n",
    "        print(f\"\\nTraining single model on reconstructed data...\")\n",
    "        !python train.py --model CNN60d --image_days 60 --pred_days 60 --use_original_format --data_version reconstructed --batch_size 64\n",
    "    \n",
    "    print(\"‚úÖ CNN60d (reconstructed) training completed\")\n",
    "else:\n",
    "    print(\"‚ùå Reconstructed data not available - skipping\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Portfolio Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN20d 2-Way Comparative Evaluation\n",
    "print(f\"=== CNN20d 2-WAY COMPARATIVE EVALUATION ===\")\n",
    "print(f\"Strategy: Monthly (I20/R20)\")\n",
    "print(f\"Paper benchmark: Sharpe = 2.16\")\n",
    "print(f\"üéØ Testing which dataset gives BEST performance!\")\n",
    "print(f\"\")\n",
    "\n",
    "ensemble_flag = \"--ensemble\" if USE_ENSEMBLE else \"\"\n",
    "\n",
    "# Original Author Data\n",
    "if CAN_TRAIN_ORIGINAL_AUTHOR:\n",
    "    print(\"üìä CNN20d - Original Author Data:\")\n",
    "    !python test.py --model CNN20d --image_days 20 --pred_days 20 {ensemble_flag} --use_original_format --data_version original_author\n",
    "    cleanup_memory()\n",
    "else:\n",
    "    print(\"‚ùå CNN20d original author model not available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Reconstructed Data\n",
    "if CAN_TRAIN_RECONSTRUCTED:\n",
    "    print(\"üìä CNN20d - Reconstructed Data:\")\n",
    "    !python test.py --model CNN20d --image_days 20 --pred_days 20 {ensemble_flag} --use_original_format --data_version reconstructed\n",
    "    cleanup_memory()\n",
    "else:\n",
    "    print(\"‚ùå CNN20d reconstructed model not available\")\n",
    "\n",
    "print(\"\\n‚úÖ CNN20d 2-way comparative evaluation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Way Comparative Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"üèÜ 2-WAY COMPARATIVE RESULTS ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "def load_result(model, data_version, ensemble=USE_ENSEMBLE):\n",
    "    \"\"\"Load performance result from JSON file\"\"\"\n",
    "    eval_type = \"ensemble\" if ensemble else \"single\"\n",
    "    \n",
    "    # Model naming based on data version\n",
    "    if data_version == 'original_author':\n",
    "        suffix = \"_original_author\"\n",
    "    else:  # 'reconstructed'\n",
    "        suffix = \"_reconstructed\"\n",
    "    \n",
    "    result_file = f\"results/{model}_I{model[3:]}R{model[3:]}{suffix}_{eval_type}_performance.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(result_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "# Focus on CNN20d for detailed comparison\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"üéØ CNN20d DETAILED COMPARISON - Monthly Strategy (I20/R20)\")\n",
    "print(f\"üìä Paper benchmark: Sharpe = 2.16\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "# Load both results\n",
    "data_versions = ['original_author', 'reconstructed']\n",
    "results = {}\n",
    "\n",
    "for version in data_versions:\n",
    "    results[version] = load_result('CNN20d', version)\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"\\n{'Dataset':<18}{'Sharpe':<10}{'Return':<12}{'Vol':<10}{'Turnover':<12}{'Status':<12}\")\n",
    "print(f\"{'-'*80}\")\n",
    "\n",
    "best_sharpe = -999\n",
    "best_version = None\n",
    "paper_benchmark = 2.16\n",
    "\n",
    "for version in data_versions:\n",
    "    result = results[version]\n",
    "    \n",
    "    if result:\n",
    "        sharpe = result['ls_sharpe_ratio']\n",
    "        annual_return = result['ls_annual_return'] * 100\n",
    "        annual_vol = result['ls_annual_vol'] * 100  \n",
    "        turnover = result['monthly_turnover']\n",
    "        \n",
    "        # Compare to paper\n",
    "        vs_paper = sharpe - paper_benchmark\n",
    "        status = f\"üìà {vs_paper:+.1f}\" if vs_paper > 0 else f\"üìâ {vs_paper:+.1f}\"\n",
    "        \n",
    "        if sharpe > best_sharpe:\n",
    "            best_sharpe = sharpe\n",
    "            best_version = version\n",
    "        \n",
    "        print(f\"{version:<18}{sharpe:<10.2f}{annual_return:<12.1f}%{annual_vol:<10.1f}%{turnover:<12.1f}%{status:<12}\")\n",
    "        \n",
    "        # Detailed metrics for each version\n",
    "        print(f\"  ‚îî‚îÄ Details: L={result['long_sharpe_ratio']:.2f}, S={result['short_sharpe_ratio']:.2f}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"{version:<18}{'N/A':<10}{'N/A':<12}{'N/A':<10}{'N/A':<12}{'‚ùå Missing':<12}\")\n",
    "\n",
    "# Winner analysis\n",
    "print(f\"\\nüèÜ PERFORMANCE RANKING:\")\n",
    "valid_results = [(v, results[v]['ls_sharpe_ratio']) for v in data_versions if results[v] is not None]\n",
    "valid_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (version, sharpe) in enumerate(valid_results):\n",
    "    medal = \"ü•á\" if i == 0 else \"ü•à\"\n",
    "    print(f\"{medal} {i+1}. {version}: {sharpe:.2f} Sharpe\")\n",
    "\n",
    "if best_version:\n",
    "    print(f\"\\nüéâ WINNER: {best_version.upper()} (Sharpe: {best_sharpe:.2f})\")\n",
    "    \n",
    "    # Compare to baseline\n",
    "    if len(valid_results) > 1:\n",
    "        baseline_version, baseline_sharpe = valid_results[-1]  # Worse performer\n",
    "        improvement = best_sharpe - baseline_sharpe\n",
    "        improvement_pct = improvement / abs(baseline_sharpe) * 100 if baseline_sharpe != 0 else 0\n",
    "        print(f\"üìà Improvement: {improvement:+.2f} Sharpe ({improvement_pct:+.1f}%)\")\n",
    "    \n",
    "    # Compare to paper benchmark  \n",
    "    vs_paper_pct = (best_sharpe - paper_benchmark) / paper_benchmark * 100\n",
    "    if best_sharpe > paper_benchmark:\n",
    "        print(f\"üöÄ BEATS paper benchmark by {best_sharpe - paper_benchmark:.2f} ({vs_paper_pct:+.1f}%)\")\n",
    "    else:\n",
    "        print(f\"üìâ Below paper benchmark by {paper_benchmark - best_sharpe:.2f} ({vs_paper_pct:.1f}%)\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "\n",
    "if len(valid_results) == 2:\n",
    "    best_version, best_sharpe = valid_results[0]\n",
    "    second_version, second_sharpe = valid_results[1]\n",
    "    \n",
    "    print(f\"   ü•á Best dataset: {best_version}\")\n",
    "    print(f\"   üìä Performance gap: {best_sharpe - second_sharpe:.2f} Sharpe\")\n",
    "    \n",
    "    # Data quality impact\n",
    "    if 'original_author' in [v[0] for v in valid_results]:\n",
    "        original_sharpe = next(sharpe for v, sharpe in valid_results if v == 'original_author')\n",
    "        reconstructed_sharpe = next(sharpe for v, sharpe in valid_results if v == 'reconstructed')\n",
    "        \n",
    "        if reconstructed_sharpe > original_sharpe:\n",
    "            print(f\"   üéØ Our reconstruction IMPROVED performance by {reconstructed_sharpe - original_sharpe:.2f} Sharpe!\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Original author data still better by {original_sharpe - reconstructed_sharpe:.2f} Sharpe\")\n",
    "            print(f\"   üîç Need to investigate reconstruction differences\")\n",
    "\n",
    "print(f\"\\nüìÅ Result files saved in: results/\")\n",
    "if os.path.exists('results'):\n",
    "    result_files = [f for f in os.listdir('results') if f.endswith('.json') and 'CNN20d' in f]\n",
    "    for f in sorted(result_files):\n",
    "        print(f\"   üìä {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}